{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of emotion&customizelambda.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivaP69/CalibrationBasedOnEmotion/blob/main/emotion%26customizelambda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5WGRXs3AGJ4",
        "outputId": "37a3e063-efe1-4b83-d4e9-ba47fc14ef98"
      },
      "source": [
        "pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b28Q8hDv1VBb"
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTAZvV321Xrw",
        "outputId": "d1bd71bf-9e37-416a-f49a-5972420c3dad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mVIXj2h1da8"
      },
      "source": [
        "ratings=pd.read_csv(\"/content/gdrive/MyDrive/ratings.csv\",parse_dates=['timestamp'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beRvUY771h4Y"
      },
      "source": [
        "tagsdf=pd.read_csv(\"/content/gdrive/MyDrive/tagsdf.csv\") # tagsdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGqt_9KeZ1Gj"
      },
      "source": [
        "tags=pd.read_csv(\"/content/gdrive/MyDrive/tag.csv\") #tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C1QL_MEZ2Yd"
      },
      "source": [
        "x= tags['movieId'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ9s2EA-1yDS",
        "outputId": "1a28990e-8d5c-41b6-deb6-14ac9ed3c0be"
      },
      "source": [
        "title_col = 'title'\n",
        "genre_col = 'genres'\n",
        "\n",
        "df_item = pd.read_csv('/content/gdrive/MyDrive/movie.csv')\n",
        "df_item = df_item[df_item[genre_col] != '(no genres listed)']  # eliminate movies that had no genre information attached\n",
        "print('dimension: ', df_item.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dimension:  (27032, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My8OPMvq1y2U"
      },
      "source": [
        "user_col = 'userId'\n",
        "item_col = 'movieId'\n",
        "value_col = 'rating'\n",
        "time_col = 'timestamp'\n",
        "\n",
        "df= ratings[ratings['rating'] >= 4.0].copy()\n",
        "ratings = df.merge(df_item, on='movieId')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jjypTCn17Rv"
      },
      "source": [
        "kaggle_df=ratings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2EW8QvZ2NQe"
      },
      "source": [
        "kaggle_df=kaggle_df.merge(tagsdf,on='movieId')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "o5gnCu5v2cQh",
        "outputId": "baee83ed-fe2c-474c-9192-147bda5f4298"
      },
      "source": [
        "kaggle_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>236</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1999-12-11 13:36:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>238</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1999-12-11 13:14:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>239</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1999-12-11 13:13:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>175</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1999-12-11 13:32:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>244</td>\n",
              "      <td>3</td>\n",
              "      <td>223</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1999-12-11 13:20:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6027296</th>\n",
              "      <td>19999790</td>\n",
              "      <td>138491</td>\n",
              "      <td>1093</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2009-03-04 01:36:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6027305</th>\n",
              "      <td>19999799</td>\n",
              "      <td>138491</td>\n",
              "      <td>2857</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2009-03-04 01:39:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6027307</th>\n",
              "      <td>19999801</td>\n",
              "      <td>138491</td>\n",
              "      <td>3186</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2009-03-04 01:38:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6027309</th>\n",
              "      <td>19999803</td>\n",
              "      <td>138491</td>\n",
              "      <td>4128</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2009-03-04 01:37:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6027310</th>\n",
              "      <td>19999804</td>\n",
              "      <td>138491</td>\n",
              "      <td>6874</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2009-07-09 23:48:57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3005919 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0  userId  movieId  rating           timestamp\n",
              "0               236       3        1     4.0 1999-12-11 13:36:47\n",
              "2               238       3       32     4.0 1999-12-11 13:14:07\n",
              "3               239       3       50     5.0 1999-12-11 13:13:38\n",
              "6               242       3      175     5.0 1999-12-11 13:32:13\n",
              "8               244       3      223     5.0 1999-12-11 13:20:44\n",
              "...             ...     ...      ...     ...                 ...\n",
              "6027296    19999790  138491     1093     4.0 2009-03-04 01:36:27\n",
              "6027305    19999799  138491     2857     5.0 2009-03-04 01:39:02\n",
              "6027307    19999801  138491     3186     5.0 2009-03-04 01:38:28\n",
              "6027309    19999803  138491     4128     4.0 2009-03-04 01:37:27\n",
              "6027310    19999804  138491     6874     4.0 2009-07-09 23:48:57\n",
              "\n",
              "[3005919 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE_BeqI82hEp"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "training_data, testing_data = train_test_split(kaggle_df, test_size=0.01, random_state=25)\n",
        "training_data,validation_data=train_test_split(training_data, test_size=0.05,random_state=25)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZxPkAmWsE8Z"
      },
      "source": [
        "kaggle_df=pd.read_csv(\"/content/gdrive/MyDrive/ratings.csv\",parse_dates=['timestamp'])\n",
        "kaggle_df= kaggle_df[kaggle_df['rating'] >= 4.0].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvNGE55GP7fb"
      },
      "source": [
        "kaggle_df = kaggle_df.merge(df_item, on='movieId')\n",
        "df_id_title= kaggle_df[[\"movieId\",'title']].drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcDWkyLFN1Uv"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trainin_data=pd.read_csv('/content/gdrive/MyDrive/training_data.csv')\n",
        "testing_data=pd.read_csv('/content/gdrive/MyDrive/testing_data.csv')\n",
        "validation_data=pd.read_csv('/content/gdrive/MyDrive/validation_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPVcFQrNM5IP"
      },
      "source": [
        "#trainin_data,validation_data=train_test_split(trainin_data, test_size=0.05,random_state=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG6-GgbtGevx"
      },
      "source": [
        "#validation_data.to_csv('/content/gdrive/MyDrive/validation_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHuV7fkl5OPH"
      },
      "source": [
        "df_id_title= kaggle_df[[\"movieId\",'title']].drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7H-PyDRNCsY"
      },
      "source": [
        "x=validation_data['userId'].tolist()\n",
        "y=testing_data['userId'].tolist()\n",
        "data=[]\n",
        "for i in x:\n",
        "  if i in y:\n",
        "    data.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvZcAj8fQia3"
      },
      "source": [
        "validation_data= validation_data.loc[validation_data['userId'].isin(data)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "wHHamHsEQzuM",
        "outputId": "47f2384e-dfe4-484f-d79d-b88fc410aba6"
      },
      "source": [
        "validation_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>405943</td>\n",
              "      <td>1178299</td>\n",
              "      <td>9610158</td>\n",
              "      <td>66492</td>\n",
              "      <td>1249</td>\n",
              "      <td>1</td>\n",
              "      <td>2004-01-18 03:40:52</td>\n",
              "      <td>Femme Nikita, La (Nikita) (1990)</td>\n",
              "      <td>Action|Crime|Romance|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1230513</td>\n",
              "      <td>1096279</td>\n",
              "      <td>2908096</td>\n",
              "      <td>19724</td>\n",
              "      <td>1597</td>\n",
              "      <td>1</td>\n",
              "      <td>2000-07-28 18:39:33</td>\n",
              "      <td>Conspiracy Theory (1997)</td>\n",
              "      <td>Drama|Mystery|Romance|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1265470</td>\n",
              "      <td>733988</td>\n",
              "      <td>18483402</td>\n",
              "      <td>127954</td>\n",
              "      <td>2291</td>\n",
              "      <td>1</td>\n",
              "      <td>2008-03-06 14:26:13</td>\n",
              "      <td>Edward Scissorhands (1990)</td>\n",
              "      <td>Drama|Fantasy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2097078</td>\n",
              "      <td>782616</td>\n",
              "      <td>13669516</td>\n",
              "      <td>94433</td>\n",
              "      <td>2959</td>\n",
              "      <td>1</td>\n",
              "      <td>2004-11-12 12:27:54</td>\n",
              "      <td>Fight Club (1999)</td>\n",
              "      <td>Action|Crime|Drama|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>522167</td>\n",
              "      <td>1787930</td>\n",
              "      <td>18359695</td>\n",
              "      <td>127063</td>\n",
              "      <td>5528</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-04-17 20:45:50</td>\n",
              "      <td>One Hour Photo (2002)</td>\n",
              "      <td>Drama|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120230</th>\n",
              "      <td>395910</td>\n",
              "      <td>780298</td>\n",
              "      <td>8916785</td>\n",
              "      <td>61633</td>\n",
              "      <td>2959</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-02-01 20:42:12</td>\n",
              "      <td>Fight Club (1999)</td>\n",
              "      <td>Action|Crime|Drama|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120231</th>\n",
              "      <td>692366</td>\n",
              "      <td>2873712</td>\n",
              "      <td>7845243</td>\n",
              "      <td>54107</td>\n",
              "      <td>6579</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-11-15 01:42:07</td>\n",
              "      <td>One, Two, Three (1961)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120232</th>\n",
              "      <td>591084</td>\n",
              "      <td>2089938</td>\n",
              "      <td>19959365</td>\n",
              "      <td>138200</td>\n",
              "      <td>6218</td>\n",
              "      <td>1</td>\n",
              "      <td>2006-03-02 21:12:10</td>\n",
              "      <td>Bend It Like Beckham (2002)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120233</th>\n",
              "      <td>141022</td>\n",
              "      <td>3002786</td>\n",
              "      <td>19049965</td>\n",
              "      <td>131822</td>\n",
              "      <td>62000</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-03-17 23:58:29</td>\n",
              "      <td>Steamroller and the Violin, The (Katok i skrip...</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120234</th>\n",
              "      <td>2101065</td>\n",
              "      <td>770917</td>\n",
              "      <td>10227636</td>\n",
              "      <td>70781</td>\n",
              "      <td>2858</td>\n",
              "      <td>1</td>\n",
              "      <td>2009-08-25 11:35:46</td>\n",
              "      <td>American Beauty (1999)</td>\n",
              "      <td>Comedy|Drama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>119771 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  ...                          genres\n",
              "0           405943  ...   Action|Crime|Romance|Thriller\n",
              "1          1230513  ...  Drama|Mystery|Romance|Thriller\n",
              "2          1265470  ...           Drama|Fantasy|Romance\n",
              "3          2097078  ...     Action|Crime|Drama|Thriller\n",
              "4           522167  ...                  Drama|Thriller\n",
              "...            ...  ...                             ...\n",
              "120230      395910  ...     Action|Crime|Drama|Thriller\n",
              "120231      692366  ...                          Comedy\n",
              "120232      591084  ...            Comedy|Drama|Romance\n",
              "120233      141022  ...                           Drama\n",
              "120234     2101065  ...                    Comedy|Drama\n",
              "\n",
              "[119771 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0DKVIdj3nP6"
      },
      "source": [
        "train_ratings= trainin_data\n",
        "test_ratings=testing_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "UVlCKHMY32wg",
        "outputId": "372f0f1b-c72d-4219-ad38-e8082b8bc2af"
      },
      "source": [
        "train_ratings.loc[:, 'rating'] = 1\n",
        "\n",
        "train_ratings.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1987153</th>\n",
              "      <td>785242</td>\n",
              "      <td>19235998</td>\n",
              "      <td>133113</td>\n",
              "      <td>2959</td>\n",
              "      <td>1</td>\n",
              "      <td>2009-03-30 15:22:00</td>\n",
              "      <td>Fight Club (1999)</td>\n",
              "      <td>Action|Crime|Drama|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213153</th>\n",
              "      <td>316857</td>\n",
              "      <td>14658884</td>\n",
              "      <td>101257</td>\n",
              "      <td>1261</td>\n",
              "      <td>1</td>\n",
              "      <td>1999-12-12 15:45:52</td>\n",
              "      <td>Evil Dead II (Dead by Dawn) (1987)</td>\n",
              "      <td>Action|Comedy|Fantasy|Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3474</th>\n",
              "      <td>358767</td>\n",
              "      <td>13114616</td>\n",
              "      <td>90599</td>\n",
              "      <td>1544</td>\n",
              "      <td>1</td>\n",
              "      <td>1999-10-17 16:49:27</td>\n",
              "      <td>Lost World: Jurassic Park, The (1997)</td>\n",
              "      <td>Action|Adventure|Sci-Fi|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840658</th>\n",
              "      <td>2391080</td>\n",
              "      <td>11130290</td>\n",
              "      <td>76911</td>\n",
              "      <td>55908</td>\n",
              "      <td>1</td>\n",
              "      <td>2008-12-28 18:51:21</td>\n",
              "      <td>Man from Earth, The (2007)</td>\n",
              "      <td>Drama|Sci-Fi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1766854</th>\n",
              "      <td>1151070</td>\n",
              "      <td>16679454</td>\n",
              "      <td>115383</td>\n",
              "      <td>508</td>\n",
              "      <td>1</td>\n",
              "      <td>1996-08-13 05:41:51</td>\n",
              "      <td>Philadelphia (1993)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0  ...                            genres\n",
              "1987153      785242  ...       Action|Crime|Drama|Thriller\n",
              "213153       316857  ...      Action|Comedy|Fantasy|Horror\n",
              "3474         358767  ...  Action|Adventure|Sci-Fi|Thriller\n",
              "840658      2391080  ...                      Drama|Sci-Fi\n",
              "1766854     1151070  ...                             Drama\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXMb8wli34eU"
      },
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "class MovieLensTrainDataset(Dataset):\n",
        "    \"\"\"MovieLens PyTorch Dataset for Training\n",
        "\n",
        "    Args:\n",
        "        ratings (pd.DataFrame): Dataframe containing the movie ratings\n",
        "        all_movieIds (list): List containing all movieIds\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ratings, all_movieIds):\n",
        "        self.users, self.items, self.labels = self.get_dataset(ratings, all_movieIds)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.items[idx], self.labels[idx]\n",
        "\n",
        "    def get_dataset(self, ratings, all_movieIds):\n",
        "        users, items, labels = [], [], []\n",
        "\n",
        "        user_item_dict=train_ratings.groupby('userId')['movieId'].apply(list).to_dict()\n",
        "\n",
        "\n",
        "        num_negatives = 4\n",
        "        for u in user_item_dict:\n",
        "            users.append(u)\n",
        "            for k in user_item_dict[u]:\n",
        "              items.append(k)\n",
        "              labels.append(1)\n",
        "            for _ in range(num_negatives):\n",
        "                negative_item = np.random.choice(all_movieIds)\n",
        "                if negative_item not in user_item_dict[u]:\n",
        "                  users.append(u)\n",
        "                  items.append(negative_item)\n",
        "                  labels.append(0)\n",
        "\n",
        "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKxsA3dt374Y"
      },
      "source": [
        "pip install pytorch-lightning\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCu3Bm9H4A3O"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch.nn as nn\n",
        "class NCF(pl.LightningModule):\n",
        "    \"\"\" Neural Collaborative Filtering (NCF)\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of unique users\n",
        "            num_items (int): Number of unique items\n",
        "            ratings (pd.DataFrame): Dataframe containing the movie ratings for training\n",
        "            all_movieIds (list): List containing all movieIds (train + test)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, num_items, ratings, all_movieIds):\n",
        "        super().__init__()\n",
        "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=8)\n",
        "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=8)\n",
        "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
        "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
        "        self.output = nn.Linear(in_features=32, out_features=1)\n",
        "        self.ratings = ratings\n",
        "        self.all_movieIds = all_movieIds\n",
        "\n",
        "    def forward(self, user_input, item_input):\n",
        "      # Pass through embedding layers\n",
        "        user_embedded = self.user_embedding(user_input)\n",
        "        item_embedded = self.item_embedding(item_input)\n",
        "\n",
        "        # Concat the two embedding layers\n",
        "        vector = torch.cat([user_embedded, item_embedded], dim=-1)\n",
        "\n",
        "        # Pass through dense layer\n",
        "        vector = nn.ReLU()(self.fc1(vector))\n",
        "        vector = nn.ReLU()(self.fc2(vector))\n",
        "\n",
        "        # Output layer\n",
        "        pred = nn.Sigmoid()(self.output(vector))\n",
        "\n",
        "        return pred\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        user_input, item_input, labels = batch\n",
        "        predicted_labels = self(user_input, item_input)\n",
        "        loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())\n",
        "        tensorboard_logs = {'train_loss': loss}\n",
        "        return {'loss': loss, 'log': tensorboard_logs}\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters())\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(MovieLensTrainDataset(self.ratings, self.all_movieIds),\n",
        "                          batch_size=512, num_workers=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifbUnPCn4D5I"
      },
      "source": [
        "num_users = kaggle_df['userId'].max()+1\n",
        "num_items = kaggle_df['movieId'].max()+1\n",
        "\n",
        "all_movieIds = kaggle_df['movieId'].unique()\n",
        "\n",
        "model = NCF(num_users, num_items, train_ratings, all_movieIds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dLsztBnVANp"
      },
      "source": [
        "all_movieIds = kaggle_df['movieId'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478,
          "referenced_widgets": [
            "6a359f08d7c042c3b2a062aa3c88f7ad"
          ]
        },
        "id": "pFsgch0W4EAi",
        "outputId": "352b8c5b-3a43-4bb3-abf0-62fcfb43db20"
      },
      "source": [
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "import torch\n",
        "#from pytorch_lightning.loggers.neptune import NeptuneLogger\n",
        "\n",
        "\n",
        "\n",
        "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
        "trainer = pl.Trainer(max_epochs=10, reload_dataloaders_every_epoch=True,\n",
        "                     progress_bar_refresh_rate=50, checkpoint_callback=True,logger=logger)\n",
        "\n",
        "trainer.fit(model)\n",
        "\n",
        "trainer.save_checkpoint(\"deep_embd.ckpt\")\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"trainer = pl.Trainer(max_epochs=5, gpus=1, reload_dataloaders_every_epoch=True,\n",
        "                     progress_bar_refresh_rate=50, logger=False, checkpoint_callback=False)\n",
        "\n",
        "trainer.fit(model)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:50: LightningDeprecationWarning: `reload_dataloaders_every_epoch` is deprecated in v1.4 and will be removed in v1.6. Please use `reload_dataloaders_every_n_epochs` in Trainer.\n",
            "  \"`reload_dataloaders_every_epoch` is deprecated in v1.4 and will be removed in v1.6.\"\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "\n",
            "  | Name           | Type      | Params\n",
            "---------------------------------------------\n",
            "0 | user_embedding | Embedding | 1.1 M \n",
            "1 | item_embedding | Embedding | 1.0 M \n",
            "2 | fc1            | Linear    | 1.1 K \n",
            "3 | fc2            | Linear    | 2.1 K \n",
            "4 | output         | Linear    | 33    \n",
            "---------------------------------------------\n",
            "2.2 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.2 M     Total params\n",
            "8.642     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a359f08d7c042c3b2a062aa3c88f7ad",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training: -1it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:406: LightningDeprecationWarning: One of the returned values {'log'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
            "  f\"One of the returned values {set(extra.keys())} has a `grad_fn`. We will detach it automatically\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'trainer = pl.Trainer(max_epochs=5, gpus=1, reload_dataloaders_every_epoch=True,\\n                     progress_bar_refresh_rate=50, logger=False, checkpoint_callback=False)\\n\\ntrainer.fit(model)'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q23xhlU7nqFr"
      },
      "source": [
        "test_user_item_dict= test_ratings.groupby('userId')['movieId'].apply(list).to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwAKWT__A_wQ"
      },
      "source": [
        "user_interacted_items = trainin_data.groupby('userId')['movieId'].apply(list).to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yYltcsSzHE1"
      },
      "source": [
        "validation_dict= validation_data.groupby('userId')['movieId'].apply(list).to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tY268ICDVEPS",
        "outputId": "95b6c8b1-f0e2-4ddb-de94-15c9fff18e7d"
      },
      "source": [
        "#User-item pairs for testing\n",
        "#test_user_item_set = set(zip(test_ratings['userId'], test_ratings['movieId']))\n",
        "test_user_item_dict= test_ratings.groupby('userId')['movieId'].apply(list).to_dict()\n",
        "\n",
        "# Dict of all items that are interacted with by each user\n",
        "user_interacted_items = trainin_data.groupby('userId')['movieId'].apply(list).to_dict() ########## training_data\n",
        "\n",
        "candidate_items={}\n",
        "interacted_items_kaggle={}\n",
        "interacted_items=[]\n",
        "test_items={}\n",
        "hits = []\n",
        "rows=[]\n",
        "predicted_labels={}\n",
        "top20_items={}\n",
        "for u in test_user_item_dict.keys():\n",
        "  if u in user_interacted_items.keys():\n",
        "\n",
        "    not_interacted_items = set(all_movieIds) - set(user_interacted_items[u])\n",
        "    selected_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n",
        "    test_items[u] = selected_not_interacted + test_user_item_dict[u]\n",
        "    #tt[u]=selected_not_interacted + test_user_item_dict[u]\n",
        "    k=len(test_items[u])\n",
        "\n",
        "\n",
        "    predicted_labels[u] = np.squeeze(model(torch.tensor([u]*k),torch.tensor(test_items[u])).detach().numpy()) # could be interpreted as score\n",
        "    top20_items[u] = [test_items[u][i] for i in np.argsort(predicted_labels[u])[::-1][0:20].tolist()] # what items in test_items are in 20 most probable predicted labels\n",
        "    candidate_items[u]=[test_items[u][i] for i in np.argsort(predicted_labels[u])[::-1][0:50].tolist()] # all items in test_items by order\n",
        "    interacted_items_kaggle[u]=df_id_title[df_id_title['movieId'].isin(user_interacted_items[u])]['title'].tolist() # title\n",
        "    #calib_recommend(candidate_items,,topn=20,lmbda=0.8)\n",
        "    for i in test_user_item_dict[u]:\n",
        "        if i in top20_items[u]:\n",
        "          hits.append(1)\n",
        "        else:\n",
        "          hits.append(0)\n",
        "\n",
        "\n",
        "a_file=open(\"/content/gdrive/MyDrive/top20_items_test.pkl\",\"wb\")\n",
        "pickle.dump(top20_items,a_file)\n",
        "a_file.close()\n",
        "\n",
        "a_file = open(\"/content/gdrive/MyDrive/candidate_items_test.pkl\", \"wb\")\n",
        "pickle.dump(candidate_items, a_file)\n",
        "a_file.close()\n",
        "\n",
        "\n",
        "a_file = open(\"/content/gdrive/MyDrive/predicted_labels_test.pkl\", \"wb\")\n",
        "pickle.dump(predicted_labels, a_file)\n",
        "a_file.close()\n",
        "\n",
        "a_file = open(\"/content/gdrive/MyDrive/interacted_items_kaggle_test.pkl\", \"wb\")\n",
        "pickle.dump(interacted_items_kaggle, a_file)\n",
        "a_file.close()\n",
        "\n",
        "a_file = open(\"/content/gdrive/MyDrive/test_items_test.pkl\", \"wb\")\n",
        "pickle.dump(test_items, a_file)\n",
        "a_file.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"The Hit Ratio @ 20 is {:.2f}\".format(np.average(hits)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Hit Ratio @ 20 is 0.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ9dbEokZPe2"
      },
      "source": [
        "\n",
        "\n",
        "a_file = open(\"/content/gdrive/MyDrive/top20_items_test.pkl\", \"rb\")\n",
        "top20_items = pickle.load(a_file)\n",
        "a_file.close()\n",
        "a_file = open(\"/content/gdrive/MyDrive/candidate_items_test.pkl\", \"rb\")\n",
        "candidate_items = pickle.load(a_file)\n",
        "a_file.close()\n",
        "a_file = open(\"/content/gdrive/MyDrive/predicted_labels_test.pkl\", \"rb\")\n",
        "predicted_labels = pickle.load(a_file)\n",
        "a_file.close()\n",
        "a_file = open(\"/content/gdrive/MyDrive/interacted_items_kaggle.pkl\", \"rb\")\n",
        "interacted_items_kaggle = pickle.load(a_file)\n",
        "a_file.close()\n",
        "\n",
        "a_file = open(\"/content/gdrive/MyDrive/test_items_test.pkl\", \"rb\")\n",
        "test_items = pickle.load(a_file)\n",
        "a_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS0wm4Qc4bwu"
      },
      "source": [
        "#User-item pairs for testing\n",
        "#test_user_item_set = set(zip(test_ratings['userId'], test_ratings['movieId']))\n",
        "validation_dict= validation_data.groupby('userId')['movieId'].apply(list).to_dict()\n",
        "\n",
        "# Dict of all items that are interacted with by each user\n",
        "user_interacted_items = trainin_data.groupby('userId')['movieId'].apply(list).to_dict() ########## training_data\n",
        "\n",
        "candidate_items={}\n",
        "interacted_items_kaggle={}\n",
        "interacted_items=[]\n",
        "test_items={}\n",
        "hits = []\n",
        "rows=[]\n",
        "predicted_labels={}\n",
        "top20_items={}\n",
        "for u in validation_dict.keys():\n",
        "    rows.append(u)\n",
        "    if u in user_interacted_items.keys():\n",
        "      #not_interacted_items = set(all_movieIds) - set(user_interacted_items[u])\n",
        "      selected_not_interacted =list(np.random.choice(list(not_interacted_items), 200))\n",
        "      #test_items[u]= validation_dict[u]\n",
        "\n",
        "      test_items[u] = selected_not_interacted + validation_dict[u]\n",
        "      #tt[u]=selected_not_interacted + test_user_item_dict[u]\n",
        "\n",
        "      k=len(test_items[u])\n",
        "\n",
        "\n",
        "      predicted_labels[u] = np.squeeze(model(torch.tensor([u]*k),torch.tensor(test_items[u])).detach().numpy()) # could be interpreted as score\n",
        "      top20_items[u] = [test_items[u][i] for i in np.argsort(predicted_labels[u])[::-1][0:20].tolist()] # what items in test_items are in 20 most probable predicted labels\n",
        "      candidate_items[u]=[test_items[u][i] for i in np.argsort(predicted_labels[u])[::-1][0:50].tolist()] # all items in test_items by order\n",
        "      interacted_items_kaggle[u]=df_id_title[df_id_title['movieId'].isin(user_interacted_items[u])]['title'].tolist() # title\n",
        "      #calib_recommend(candidate_items,,topn=20,lmbda=0.8)\n",
        "      for i in validation_dict[u]:\n",
        "          if i in top20_items[u]:\n",
        "            hits.append(1)\n",
        "          else:\n",
        "            hits.append(0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "a_file=open(\"/content/gdrive/MyDrive/top20_items.pkl\",\"wb\")\n",
        "pickle.dump(top20_items,a_file)\n",
        "a_file.close()\n",
        "\n",
        "a_file = open(\"/content/gdrive/MyDrive/candidate_items.pkl\", \"wb\")\n",
        "pickle.dump(candidate_items, a_file)\n",
        "a_file.close()\n",
        "\n",
        "\n",
        "a_file = open(\"/content/gdrive/MyDrive/predicted_labels.pkl\", \"wb\")\n",
        "pickle.dump(predicted_labels, a_file)\n",
        "a_file.close()\n",
        "\n",
        "a_file = open(\"/content/gdrive/MyDrive/interacted_items_kaggle.pkl\", \"wb\")\n",
        "pickle.dump(interacted_items_kaggle, a_file)\n",
        "a_file.close()\n",
        "\n",
        "a_file = open(\"/content/gdrive/MyDrive/test_items.pkl\", \"wb\")\n",
        "pickle.dump(test_items, a_file)\n",
        "a_file.close()\n",
        "\n",
        "print(hits)\n",
        "print(\"The Hit Ratio @ 20 is {:.2f}\".format(np.average(hits)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH9-_7zEljur"
      },
      "source": [
        "\n",
        "\n",
        "a_file = open(\"/content/gdrive/MyDrive/top20_items.pkl\", \"rb\")\n",
        "top20_items = pickle.load(a_file)\n",
        "a_file.close()\n",
        "a_file = open(\"/content/gdrive/MyDrive/candidate_items.pkl\", \"rb\")\n",
        "candidate_items = pickle.load(a_file)\n",
        "a_file.close()\n",
        "a_file = open(\"/content/gdrive/MyDrive/predicted_labels.pkl\", \"rb\")\n",
        "predicted_labels = pickle.load(a_file)\n",
        "a_file.close()\n",
        "a_file = open(\"/content/gdrive/MyDrive/interacted_items_kaggle.pkl\", \"rb\")\n",
        "interacted_items_kaggle = pickle.load(a_file)\n",
        "a_file.close()\n",
        "\n",
        "a_file = open(\"/content/gdrive/MyDrive/test_items.pkl\", \"rb\")\n",
        "test_items = pickle.load(a_file)\n",
        "a_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWsZ30Gm2Q6q"
      },
      "source": [
        "#interacted # validationd data\n",
        "\n",
        "\n",
        "def interaction_ditribution_val(tagsdf,user_interacted_items):\n",
        "\n",
        "    pr=0.001\n",
        "    beta=0.001\n",
        "\n",
        "\n",
        "    finall_interatced_ditribution={}\n",
        "    for user_id in user_interacted_items_val.keys() :\n",
        "      distr={}\n",
        "      interacted_distr={}\n",
        "\n",
        "      df_user = tagsdf.loc[tagsdf['movieId'].isin(user_interacted_items[user_id])]\n",
        "      df_user= df_user.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "\n",
        "      for col in df_user.columns:\n",
        "        interacted_distr[col]=(df_user[col].sum())* (1-beta) + beta*pr\n",
        "\n",
        "\n",
        "\n",
        "      interacted_distr = {k: v / total for total in (sum(interacted_distr.values()),) for k, v in interacted_distr.items()}\n",
        "      k= len(interacted_distr.keys())\n",
        "      for emotion, score in interacted_distr.items():\n",
        "        normalize_emotions = round(score /(k) , 3)\n",
        "        distr[emotion] = normalize_emotions\n",
        "\n",
        "\n",
        "\n",
        "      finall_interatced_ditribution[user_id]=distr\n",
        "    return finall_interatced_ditribution\n",
        "\n",
        "\n",
        "user_interacted_items_val = validation_data.groupby('userId')['movieId'].apply(list).to_dict() ########## training_data\n",
        "interacted_distr_val= interaction_ditribution_val(tagsdf,user_interacted_items_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVH9Q4RMivN0"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_kl_divergence(interacted_distr, reco_distr, alpha=0.01):\n",
        "  kl_div = 0.\n",
        "  for emotion, score in interacted_distr.items():\n",
        "      reco_score = reco_distr.get(emotion, 0.)\n",
        "      if score==0 and reco_score==0:\n",
        "        kl_div+=0\n",
        "      else:\n",
        "        reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "        kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "  return kl_div\n",
        "\n",
        "\n",
        "def q_distr(list_items):\n",
        "\n",
        "    interacted_distr={}\n",
        "\n",
        "    df_user = tagsdf.loc[tagsdf['movieId'].isin(list_items)]\n",
        "    df_user= df_user.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "\n",
        "    for col in df_user.columns:\n",
        "      interacted_distr[col]=(df_user[col].sum())\n",
        "\n",
        "    interacted_distr = {k: v / total for total in (sum(interacted_distr.values()),) for k, v in interacted_distr.items()}\n",
        "\n",
        "    return interacted_distr\n",
        "\n",
        "\n",
        "kl_divergence={}\n",
        "for user_id in top20_items.keys():\n",
        "\n",
        "  reco_distribution = q_distr(top20_items[user_id])\n",
        "  kl_divergence[user_id] = compute_kl_divergence(interacted_distr[user_id],reco_distribution)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3076OlUpF2Jq"
      },
      "source": [
        "import heapq\n",
        "from operator import itemgetter\n",
        "topitems = heapq.nlargest(500, kl_divergence.items(), key=itemgetter(1))  # Use .iteritems() on Py2\n",
        "topitemsasdict = dict(topitems)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnd3WzRlY_Z0"
      },
      "source": [
        "rows=topitemsasdict.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUmsH7bWTUoc",
        "outputId": "eb253bed-0d01-41dc-8502-d026e05cd099"
      },
      "source": [
        "len(topitemsasdict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjPKUANFOqtC"
      },
      "source": [
        "rows= topitemsasdict.keys()\n",
        "#rows=(random.sample(rows, 500))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55bib3fHFlN9"
      },
      "source": [
        "for i in rows:\n",
        "  if i not in topitemsasdict.keys():\n",
        "    print(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce-zU3l8DfGs"
      },
      "source": [
        "import heapq\n",
        "from operator import itemgetter\n",
        "topitems = heapq.nsmallest(500, kl_divergence.items(), key=itemgetter(1))  # Use .iteritems() on Py2\n",
        "topitemsasdict = dict(topitems)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y5pNuG_Jg7D"
      },
      "source": [
        "import random\n",
        "rows= topitemsasdict.keys()\n",
        "rows=(random.sample(rows, 500))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEmQ5uOu7Mg9"
      },
      "source": [
        "import datetime\n",
        "def intersection(lst1, lst2):\n",
        "    return list(set(lst1) & set(lst2))\n",
        "\n",
        "def difference(lst1,lst2):\n",
        "  return list(set(lst1) - set(lst2))\n",
        "\n",
        "def Recall(test_user_item_dict,topn,final_calibrated_list_kaggle):\n",
        "\n",
        "\n",
        "  recall_second_reco=0\n",
        "  i=1\n",
        "\n",
        "  for user_id in final_calibrated_list_kaggle.keys() :\n",
        "\n",
        "    Likes =test_user_item_dict[user_id]\n",
        "  # calculate recall (reco & likes)\n",
        "\n",
        "\n",
        "    TP_reco=intersection(Likes,final_calibrated_list_kaggle[user_id])\n",
        "    FN_reco=difference(Likes,final_calibrated_list_kaggle[user_id])\n",
        "\n",
        "    #recall_init_reco= len(TP_reco)/(len(TP_reco)+len(FN_reco)) if (len(TP_reco)+len(FN_reco))!=0 else 1\n",
        "    recall_init_reco=len(TP_reco)/len(test_user_item_dict[user_id]) if len(test_user_item_dict[user_id])!=0 else 1\n",
        "    #recall_init_reco=len(TP_reco)/20\n",
        "    recall_second_reco+=recall_init_reco\n",
        "    print(datetime.datetime.now())\n",
        "    print(\"\\nRecall of simple recommendation by model in\" + str(i), \" \", \"is : \", recall_second_reco / i)\n",
        "    i+=1\n",
        "  recall_finall_reco = recall_second_reco/len(rows)\n",
        "\n",
        "  #recall_sum[user_id]=recall_finall_reco\n",
        "\n",
        "  print(\"recall of recommendation : \",recall_finall_reco )\n",
        "\n",
        "\n",
        "topn=20\n",
        "\n",
        "\n",
        "Recall(test_user_item_dict,topn,final_calibrated_list_kaggle)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"lmbda=0.8\n",
        "topn=20\n",
        "model=bpr\n",
        "\n",
        "rows=finall_test_rows\n",
        "\n",
        "Recall(rows,inter,user_item_train,user_item_test,topn,bpr,index2item,item_mapping,reco_items)\"\"\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRxuZci8Ag8x"
      },
      "source": [
        "# find reco to nlargest when no calibration\n",
        "simple_list={}\n",
        "for key in rows:\n",
        "  simple_list[key]=top20_items[key]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw_kU-wbEYmf",
        "outputId": "34607955-50f9-47b1-96d4-04340f2c53a5"
      },
      "source": [
        "# calculate the average of KL when lambda=0\n",
        "finall=[]\n",
        "for k,v in kl_divergence.items():\n",
        "  if k in rows:\n",
        "    finall.append(v)\n",
        "sum(finall)/len(rows)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.37995520079379236"
            ]
          },
          "execution_count": 171,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg23uAKaIDOp"
      },
      "source": [
        "# /content/gdrive/MyDrive/final_calibrated_list_kaggle_0.5_largest.pkl\n",
        "a_file = open(\"/content/gdrive/MyDrive/final_calibrated_list_kaggle_variance_largest.pkl\", \"rb\")\n",
        "calib = pickle.load(a_file)\n",
        "a_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjQhiZCGQdNn"
      },
      "source": [
        "user_interacted_items_val.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-d96BF1Oxr1"
      },
      "source": [
        "rows=[11, 17, 22, 23, 24, 29, 44, 49, 53, 55, 62, 63, 69,]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Q2Y6lTIhao"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_kl_divergence(interacted_distr, reco_distr, alpha=0.01):\n",
        "  kl_div = 0.\n",
        "  for emotion, score in interacted_distr.items():\n",
        "      reco_score = reco_distr.get(emotion, 0.)\n",
        "      if score==0 and reco_score==0:\n",
        "        kl_div+=0\n",
        "      else:\n",
        "        reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "        kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "  return kl_div\n",
        "\n",
        "\n",
        "def q_distr(list_items):\n",
        "\n",
        "    interacted_distr={}\n",
        "\n",
        "    df_user = tagsdf.loc[tagsdf['movieId'].isin(list_items)]\n",
        "    df_user= df_user.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "\n",
        "    for col in df_user.columns:\n",
        "      interacted_distr[col]=(df_user[col].sum())\n",
        "\n",
        "    interacted_distr = {k: v / total for total in (sum(interacted_distr.values()),) for k, v in interacted_distr.items()}\n",
        "\n",
        "    return interacted_distr\n",
        "\n",
        "calib=simple_list\n",
        "kl={}\n",
        "for user_id in calib.keys():\n",
        "\n",
        "  reco_distribution = q_distr(calib[user_id])\n",
        "  kl[user_id] = compute_kl_divergence(interacted_distr[user_id],reco_distribution)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDAIUudQI1Gr",
        "outputId": "60cc4834-0146-441f-d2e3-9621a44ada5f"
      },
      "source": [
        "finall=[]\n",
        "for k,v in kl.items():\n",
        "  if k in rows:\n",
        "    finall.append(v)\n",
        "sum(finall)/len(rows)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.380649976700031"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L0kJD0sCrfw"
      },
      "source": [
        "#interacted\n",
        "\n",
        "#emotion\n",
        "def interaction_ditribution(users,tagsdf,user_interacted_items):\n",
        "\n",
        "    pr=0.001\n",
        "    beta=0.001\n",
        "\n",
        "\n",
        "    finall_interatced_ditribution={}\n",
        "    for user_id in users:\n",
        "      distr={}\n",
        "      interacted_distr={}\n",
        "\n",
        "      df_user = tagsdf.loc[tagsdf['movieId'].isin(user_interacted_items[user_id])]\n",
        "      df_user= df_user.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "\n",
        "      for col in df_user.columns:\n",
        "        interacted_distr[col]=(df_user[col].sum())* (1-beta) + beta*pr\n",
        "\n",
        "\n",
        "\n",
        "      interacted_distr = {k: v / total for total in (sum(interacted_distr.values()),) for k, v in interacted_distr.items()}\n",
        "      k= len(interacted_distr.keys())\n",
        "      for emotion, score in interacted_distr.items():\n",
        "        normalize_emotions = round(score /(k) , 3)\n",
        "        distr[emotion] = normalize_emotions\n",
        "\n",
        "\n",
        "\n",
        "      finall_interatced_ditribution[user_id]=distr\n",
        "    return finall_interatced_ditribution\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b4IhlbIeEiU"
      },
      "source": [
        "users=validation_data['userId'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2lNKd-kXKt_"
      },
      "source": [
        "users=validation_data['userId'].tolist()\n",
        "interacted_distr=interaction_ditribution(users,tagsdf, user_interacted_items)\n",
        "a_file = open(\"/content/gdrive/MyDrive/interacted_distr_val.pkl\", \"wb\")\n",
        "pickle.dump(interacted_distr, a_file)\n",
        "a_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeQYAlgAo20v"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYCAgjaVHf4E"
      },
      "source": [
        "df=pd.read_csv(\"/content/gdrive/MyDrive/df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_oS3G8dG2AA"
      },
      "source": [
        "#interacted\n",
        "\n",
        "# genres\n",
        "def interaction_ditribution(users,tagsdf,user_interacted_items):\n",
        "\n",
        "    pr=0.001\n",
        "    beta=0.001\n",
        "\n",
        "\n",
        "    finall_interatced_ditribution={}\n",
        "    for user_id in users:\n",
        "      distr={}\n",
        "      interacted_distr={}\n",
        "\n",
        "      df_user = tagsdf.loc[tagsdf['movieId'].isin(user_interacted_items[user_id])]\n",
        "      df_user= df_user.drop(['Unnamed: 0', 'movieId','title'], axis=1)\n",
        "\n",
        "      for col in df_user.columns:\n",
        "        interacted_distr[col]=(df_user[col].sum())* (1-beta) + beta*pr\n",
        "\n",
        "\n",
        "      # between zero and one\n",
        "\n",
        "      interacted_distr = {k: v / total for total in (sum(interacted_distr.values()),) for k, v in interacted_distr.items()}\n",
        "      # sum to one\n",
        "      k= len(interacted_distr.keys())\n",
        "      for genre, score in interacted_distr.items():\n",
        "        normalize_genre = round(score /(k) , 3)\n",
        "        distr[genre] =  normalize_genre\n",
        "\n",
        "\n",
        "\n",
        "      finall_interatced_ditribution[user_id]=distr\n",
        "    return finall_interatced_ditribution\n",
        "\n",
        "users=validation_data['userId'].tolist()\n",
        "interacted_distr=interaction_ditribution(users,df, user_interacted_items)\n",
        "a_file = open(\"/content/gdrive/MyDrive/interacted_distr_val_genre.pkl\", \"wb\")\n",
        "pickle.dump(interacted_distr, a_file)\n",
        "a_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXxWcpHYDXRc"
      },
      "source": [
        "interacted_distr=interaction_ditribution(test_user_item_dict,tagsdf, user_interacted_items)\n",
        "a_file = open(\"/content/gdrive/MyDrive/interacted_distr.pkl\", \"wb\")\n",
        "pickle.dump(interacted_distr, a_file)\n",
        "a_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6zpIZpjETVk"
      },
      "source": [
        "a_file = open(\"/content/gdrive/MyDrive/interacted_distr_val_genre.pkl\", \"rb\")\n",
        "interacted_distr = pickle.load(a_file)\n",
        "a_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IoGwdhjGaK5",
        "outputId": "785a5239-ca83-4327-fabe-b28e6ff5fdf4"
      },
      "source": [
        "P={\"a\":1, \"b\":2, \"c\":3}\n",
        "mp=sum(P.values())/len(P)\n",
        "d2 = {key: (abs(value-mp))**2 for key,value in P.items()}\n",
        "print(sum(d2.values()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76Dz-qFUIbMZ"
      },
      "source": [
        "# define rows randomly\n",
        "import random\n",
        "rows= test_user_item_dict.keys()\n",
        "rows=(random.sample(rows, 500))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsILiRYKEo4R"
      },
      "source": [
        "# cusomaized lambda\n",
        "\n",
        "\n",
        "def variance(rows,P):\n",
        "  lmbda={}\n",
        "  for user_id in rows:\n",
        "   mp= sum(P[user_id].values())/len(P[user_id])\n",
        "   d2 = {key: abs((value-mp))**2 for key,value in P[user_id].items()}\n",
        "   lmbda[user_id]= 1- (sum(d2.values())/len(P[user_id]))\n",
        "  return lmbda\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IteMucM5Ryn"
      },
      "source": [
        "with open(\"/content/gdrive/MyDrive/rows.txt\", \"w\") as f:\n",
        "    for s in rows:\n",
        "        f.write(str(s) +\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tle0Mp3nJkjR"
      },
      "source": [
        "score = []\n",
        "with open(\"/content/gdrive/MyDrive/rows.txt\", \"r\") as f:\n",
        "  for line in f:\n",
        "    score.append(int(line.strip()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvgqX_pHQWcc"
      },
      "source": [
        "rows=score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcMglOTS3Cjl",
        "outputId": "fb666464-57db-4d53-f37e-c5135cb4899e"
      },
      "source": [
        "class CalibratedListProduction():\n",
        "  def __init__(self,topn):\n",
        "\n",
        "    self.topn=topn\n",
        "\n",
        "\n",
        "\n",
        "  def compute_kl_divergence(self,interacted_distr, reco_distr, alpha=0.01):\n",
        "      kl_div = 0.\n",
        "      for emotion, score in interacted_distr.items():\n",
        "          reco_score = reco_distr.get(emotion, 0.)\n",
        "          if score==0 and reco_score==0:\n",
        "            kl_div+=0\n",
        "          else:\n",
        "            reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "            kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "      return kl_div\n",
        "\n",
        "\n",
        "\n",
        "  def compute_utility(self,reco_distr, interacted_distr,total_score,lmbda):\n",
        "      \"\"\"\n",
        "      Our objective function for computing the utility score for\n",
        "      the list of recommended items.\n",
        "\n",
        "      lmbda : float, 0.0 ~ 1.0, default 0.5\n",
        "          Lambda term controls the score and calibration tradeoff,\n",
        "          the higher the lambda the higher the resulting recommendation\n",
        "          will be calibrated. Lambda is keyword in Python, so it's\n",
        "          lmbda instead ^^\n",
        "      \"\"\"\n",
        "\n",
        "      kl_div = self.compute_kl_divergence(interacted_distr,reco_distr)\n",
        "      # kl divergence is the lower the better, while score is\n",
        "      # the higher the better so remember to negate it in the calculation\n",
        "      utility = (1 - lmbda) * total_score - lmbda * kl_div\n",
        "      return utility\n",
        "\n",
        "\n",
        "  def calib_recommend(self,candidate,interacted_distr,test_items,predicted_labels,tagsdf,lmbda):\n",
        "\n",
        "      \"\"\"\n",
        "      start with an empty recommendation list,\n",
        "      loop over the topn cardinality, during each iteration\n",
        "      update the list with the item that maximizes the utility function.\n",
        "      \"\"\"\n",
        "      calib_reco=[]\n",
        "      calib_distr={}\n",
        "      for _ in range(self.topn):\n",
        "          max_utility = -np.inf\n",
        "          for item in candidate:  # candidate items\n",
        "\n",
        "\n",
        "              total_score=0\n",
        "              if item in calib_reco: # ignore duplicate items\n",
        "                  continue\n",
        "\n",
        "              probable_calib = calib_reco + [item]\n",
        "\n",
        "\n",
        "              df_calib =tagsdf.loc[tagsdf['movieId'].isin(probable_calib)]\n",
        "\n",
        "              df_calib= df_calib.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "              for col in df_calib.columns:\n",
        "                calib_distr[col]=df_calib[col].sum()\n",
        "              calib_distr= {k: v / total for total in (sum(calib_distr.values()),) for k, v in calib_distr.items()}\n",
        "              k= len(calib_distr.keys())\n",
        "              for emotion, score in calib_distr.items():\n",
        "                      normalize_emotions = round(score /(k) , 3)\n",
        "                      calib_distr[emotion] = normalize_emotions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "              st = set(\n",
        "\n",
        "              )\n",
        "              indexes= ([i for i, e in enumerate(test_items) if e in st])\n",
        "\n",
        "              #indexes=[i for i, val in enumerate(test_items) if val in probable_calib]\n",
        "\n",
        "              scores=[]\n",
        "              for i in indexes:\n",
        "                #print('predi',predicted_labels[i])\n",
        "\n",
        "                scores.append(predicted_labels[i])\n",
        "              #print(scores)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "              total_score= sum(scores)\n",
        "\n",
        "              #print(\"total_score\", total_score)\n",
        "\n",
        "              utility = self.compute_utility(calib_distr,interacted_distr,total_score,lmbda) # add item to best_item if increase utility of calib_reco\n",
        "              if utility > max_utility:\n",
        "                  max_utility = utility\n",
        "                  best_item = item\n",
        "\n",
        "          calib_reco.append(best_item)\n",
        "\n",
        "      return calib_reco\n",
        "\n",
        "\n",
        "\n",
        "  def calibrated_final_list(self,interacted_items_kaggle,candidate_items,test_items,predicted_labels,rows,interacted_distr,tagsdf,lmbda):\n",
        "\n",
        "    calibrated_recommendations={}\n",
        "    for user_id in rows:\n",
        "      if user_id in interacted_distr.keys() & test_items.keys():\n",
        "        calibrated_recommendations[user_id]=self.calib_recommend(candidate_items[user_id], interacted_distr[user_id],test_items[user_id],predicted_labels[user_id],tagsdf,lmbda[user_id])\n",
        "    return calibrated_recommendations\n",
        "\n",
        "\n",
        "CalibratedList = CalibratedListProduction(20)\n",
        "#rows= conversion(finall_test_rows,finall_test)\n",
        "\n",
        "lmbda= variance(rows, interacted_distr)\n",
        "\n",
        "final_calibrated_list_kaggle =CalibratedList.calibrated_final_list(interacted_items_kaggle,candidate_items,test_items ,predicted_labels,rows,interacted_distr,tagsdf,lmbda)\n",
        "print(\"completed\")\n",
        "a_file = open(\"/content/gdrive/MyDrive/final_calibrated_list_kaggle_variance.pkl\", \"wb\")\n",
        "pickle.dump(final_calibrated_list_kaggle, a_file)\n",
        "a_file.close()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log2\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRlg8QMECj8s"
      },
      "source": [
        "tagsdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqTfutwvCdma"
      },
      "source": [
        "#emotion\n",
        "Unnamed: 0\n",
        "df1=tagsdf.drop('Unnamed: 0',axis=1)\n",
        "df1.set_index(\"movieId\", drop=True, inplace=True)\n",
        "dictionary = df1.to_dict(orient=\"index\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJaRLqBqWzsy",
        "outputId": "d01c7b45-9254-413e-d705-b63195c636d1"
      },
      "source": [
        "class CalibratedListProduction():\n",
        "  def __init__(self,topn):\n",
        "\n",
        "    self.topn=topn\n",
        "\n",
        "\n",
        "\n",
        "  def compute_kl_divergence(self,interacted_distr, reco_distr, alpha=0.01):\n",
        "      kl_div = 0.\n",
        "      for emotion, score in interacted_distr.items():\n",
        "          reco_score = reco_distr.get(emotion, 0.)\n",
        "          if score==0 and reco_score==0:\n",
        "            kl_div+=0\n",
        "          else:\n",
        "            reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "            kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "      return kl_div\n",
        "\n",
        "\n",
        "\n",
        "  def compute_utility(self,reco_distr, interacted_distr,total_score,lmbda):\n",
        "      \"\"\"\n",
        "      Our objective function for computing the utility score for\n",
        "      the list of recommended items.\n",
        "\n",
        "      lmbda : float, 0.0 ~ 1.0, default 0.5\n",
        "          Lambda term controls the score and calibration tradeoff,\n",
        "          the higher the lambda the higher the resulting recommendation\n",
        "          will be calibrated. Lambda is keyword in Python, so it's\n",
        "          lmbda instead ^^\n",
        "      \"\"\"\n",
        "\n",
        "      kl_div = self.compute_kl_divergence(interacted_distr,reco_distr)\n",
        "      # kl divergence is the lower the better, while score is\n",
        "      # the higher the better so remember to negate it in the calculation\n",
        "      utility = (1 - lmbda) * total_score - lmbda * kl_div\n",
        "      return utility\n",
        "\n",
        "\n",
        "  def calib_recommend(self,candidate,interacted_distr,test_items,predicted_labels,tagsdf,lmbda):\n",
        "\n",
        "      \"\"\"\n",
        "      start with an empty recommendation list,\n",
        "      loop over the topn cardinality, during each iteration\n",
        "      update the list with the item that maximizes the utility function.\n",
        "      \"\"\"\n",
        "      final_calibration_list=[]\n",
        "      calib_distr={}\n",
        "      calib_reco=[]\n",
        "      v={}\n",
        "      for _ in range(self.topn):\n",
        "          max_utility = -np.inf\n",
        "          for item in candidate:  # candidate items\n",
        "\n",
        "\n",
        "              total_score=0\n",
        "              if item in calib_reco: # ignore duplicate items\n",
        "                  continue\n",
        "\n",
        "              probable_calib = calib_reco + [item]\n",
        "\n",
        "\n",
        "              calib_distr={k:dictionary[k] for k in probable_calib if k in dictionary}\n",
        "\n",
        "              h=sum((Counter(d) for d in calib_distr.values()), Counter())\n",
        "              v= {k: v / total for total in (sum(h.values()),) for k, v in h.items()}\n",
        "\n",
        "              k= len(v.keys())\n",
        "              for emotion, score in v.items():\n",
        "                      normalize_emotions = round(score /(k) , 3)\n",
        "                      v[emotion] = normalize_emotions\n",
        "\n",
        "\n",
        "\n",
        "              st = set(probable_calib)\n",
        "              indexes= ([i for i, e in enumerate(test_items) if e in st])\n",
        "\n",
        "              #indexes=[i for i, val in enumerate(test_items) if val in probable_calib]\n",
        "\n",
        "              scores=[]\n",
        "              for i in indexes:\n",
        "                #print('predi',predicted_labels[i])\n",
        "\n",
        "                scores.append(predicted_labels[i])\n",
        "              #print(scores)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "              total_score= sum(scores)\n",
        "\n",
        "              #print(\"total_score\", total_score)\n",
        "\n",
        "              utility = self.compute_utility(calib_distr,interacted_distr,total_score,lmbda) # add item to best_item if increase utility of calib_reco\n",
        "              if utility > max_utility:\n",
        "                  max_utility = utility\n",
        "                  best_item = item\n",
        "\n",
        "          calib_reco.append(best_item)\n",
        "\n",
        "      return calib_reco\n",
        "\n",
        "\n",
        "\n",
        "  def calibrated_final_list(self,interacted_items_kaggle,candidate_items,test_items,predicted_labels,rows,interacted_distr,tagsdf,lmbda):\n",
        "\n",
        "    calibrated_recommendations={}\n",
        "    for user_id in rows:\n",
        "      if user_id in interacted_distr.keys() & test_items.keys():\n",
        "        calibrated_recommendations[user_id]=self.calib_recommend(candidate_items[user_id], interacted_distr[user_id],test_items[user_id],predicted_labels[user_id],tagsdf,lmbda)\n",
        "    return calibrated_recommendations\n",
        "\n",
        "\n",
        "CalibratedList = CalibratedListProduction(20)\n",
        "#rows= conversion(finall_test_rows,finall_test)\n",
        "\n",
        "lmbda= 0.8\n",
        "\n",
        "final_calibrated_list_kaggle =CalibratedList.calibrated_final_list(interacted_items_kaggle,candidate_items,test_items ,predicted_labels,rows,interacted_distr,tagsdf,lmbda)\n",
        "print(\"completed\")\n",
        "a_file = open(\"/content/gdrive/MyDrive/final_calibrated_list_kaggle.pkl\", \"wb\")\n",
        "pickle.dump(final_calibrated_list_kaggle, a_file)\n",
        "a_file.close()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsSVU2MIarVZ"
      },
      "source": [
        "a_file = open(\"/content/gdrive/MyDrive/final_calibrated_list_kaggle_variance_largest.pkl\", \"wb\")\n",
        "pickle.dump(final_calibrated_list_kaggle, a_file)\n",
        "a_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjBeARMClbGF"
      },
      "source": [
        "#val distribution\n",
        "def compute_kl_divergence_val(int, val_distr, alpha=0.01):\n",
        "  kl_div = 0.\n",
        "  for emotion, score in int.items():\n",
        "      reco_score = val_distr.get(emotion, 0.)\n",
        "      if score==0 and reco_score==0:\n",
        "        kl_div+=0\n",
        "      else:\n",
        "        reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "        kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "  return kl_div"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN8JTg9WL10z",
        "outputId": "d09b85d2-f830-47fb-c769-4bed915ee032"
      },
      "source": [
        "# genre\n",
        "# validation data distribution and its difference to history of user\n",
        "##### for genre\n",
        "users=validation_data['userId'].tolist()\n",
        "\n",
        "\n",
        "validation_dict= validation_data.groupby('userId')['movieId'].apply(list).to_dict()\n",
        "KLD_val={}\n",
        "val_distr={}\n",
        "for user_id in users:\n",
        "  if user_id in interacted_distr.keys():\n",
        "    distr={}\n",
        "    interacted_distr_val={}\n",
        "\n",
        "    df_user = df.loc[tagsdf['movieId'].isin(validation_dict[user_id])]\n",
        "    df_user= df_user.drop(['Unnamed: 0', 'movieId','title'], axis=1)\n",
        "\n",
        "    for col in df_user.columns:\n",
        "      interacted_distr_val[col]=df_user[col].sum()\n",
        "\n",
        "\n",
        "\n",
        "    interacted_distr_val = {k: v / total for total in (sum(interacted_distr_val.values()),) for k, v in interacted_distr_val.items()}\n",
        "    k= len(interacted_distr_val.keys())\n",
        "    for genre, score in interacted_distr_val.items():\n",
        "      normalize_genre = round(score /(k) , 3)\n",
        "      distr[genre] = normalize_genre\n",
        "    val_distr[user_id]=distr # distr of user in validation data\n",
        "    KLD_val[user_id]= compute_kl_divergence_val(interacted_distr[user_id],val_distr[user_id]) # kld validation user and history\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log2\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in double_scalars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWExpVW5iLSn",
        "outputId": "08caa01e-711a-4e69-b92e-d5e41c208ee8"
      },
      "source": [
        "\n",
        "# validation data distribution and its difference to history of user\n",
        "\n",
        "users=validation_data['userId'].tolist()\n",
        "\n",
        "\n",
        "validation_dict= validation_data.groupby('userId')['movieId'].apply(list).to_dict()\n",
        "KLD_val={}\n",
        "val_distr={}\n",
        "for user_id in users:\n",
        "  if user_id in interacted_distr.keys():\n",
        "    distr={}\n",
        "    interacted_distr_val={}\n",
        "\n",
        "    df_user = tagsdf.loc[tagsdf['movieId'].isin(validation_dict[user_id])]\n",
        "    df_user= df_user.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "\n",
        "    for col in df_user.columns:\n",
        "      interacted_distr_val[col]=df_user[col].sum()\n",
        "\n",
        "\n",
        "\n",
        "    interacted_distr_val = {k: v / total for total in (sum(interacted_distr_val.values()),) for k, v in interacted_distr_val.items()}\n",
        "    k= len(interacted_distr_val.keys())\n",
        "    for emotion, score in interacted_distr_val.items():\n",
        "      normalize_emotions = round(score /(k) , 3)\n",
        "      distr[emotion] = normalize_emotions\n",
        "    val_distr[user_id]=distr # distr of user in validation data\n",
        "    KLD_val[user_id]= compute_kl_divergence_val(interacted_distr[user_id],val_distr[user_id]) # kld validation user and history\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log2\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGyAm4A9tv8q"
      },
      "source": [
        "import random\n",
        "rows=validation_dict.keys()\n",
        "rows=(random.sample(rows, 500))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV3MZMpSOxkz"
      },
      "source": [
        "\n",
        "#!!!!!!!!!!!!!!!!!\n",
        "#genre # genre\n",
        "\n",
        "#fisrt idea\n",
        "\n",
        "class CalibratedListProduction():\n",
        "  def __init__(self,topn):\n",
        "\n",
        "    self.topn=topn\n",
        "\n",
        "\n",
        "\n",
        "  def compute_kl_divergence(self,interacted_distr, reco_distr, alpha=0.01):\n",
        "      kl_div = 0.\n",
        "      for emotion, score in interacted_distr.items():\n",
        "          reco_score = reco_distr.get(emotion, 0.)\n",
        "          if score==0 and reco_score==0:\n",
        "            kl_div+=0\n",
        "          else:\n",
        "             if score!=0:\n",
        "              reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "              kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "      return kl_div\n",
        "  def kl_divergence(self,p, q):\n",
        "    return (p * np.log2(p/q))\n",
        "    #for i in range(len(p)))\n",
        "\n",
        "\n",
        "  def js_divergence(self,p, q):\n",
        "    m = 0.5 * (p + q)\n",
        "    return 0.5 * kl_divergence(p, m) + 0.5 * kl_divergence(q, m)\n",
        "\n",
        "  def compute_utility(self,reco_distr, interacted_distr,total_score,lmbda):\n",
        "      \"\"\"\n",
        "      Our objective function for computing the utility score for\n",
        "      the list of recommended items.\n",
        "\n",
        "      lmbda : float, 0.0 ~ 1.0, default 0.5\n",
        "          Lambda term controls the score and calibration tradeoff,\n",
        "          the higher the lambda the higher the resulting recommendation\n",
        "          will be calibrated. Lambda is keyword in Python, so it's\n",
        "          lmbda instead ^^\n",
        "      \"\"\"\n",
        "\n",
        "      kl_div = self.compute_kl_divergence(interacted_distr,reco_distr)\n",
        "\n",
        "      # kl divergence is the lower the better, while score is\n",
        "      # the higher the better so remember to negate it in the calculation\n",
        "      utility = (1 - lmbda) * total_score - lmbda * kl_div\n",
        "      return utility\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def calib_recommend(self,candidate,interacted_distr,test_items,predicted_labels,df,custom,val_distr,validation_dict,KLD_val):\n",
        "\n",
        "      \"\"\"\n",
        "      start with an empty recommendation list,\n",
        "      loop over the topn cardinality, during each iteration\n",
        "      update the list with the item that maximizes the utility function.\n",
        "      \"\"\"\n",
        "      final_calibration_list=[]\n",
        "      calib_distr={}\n",
        "      max=-np.inf\n",
        "      Best_lmbda=0\n",
        "      for lmbda in [0,0.3,0.5,0.8,0.9]:\n",
        "        calib_reco=[]\n",
        "        for _ in range(self.topn):\n",
        "            max_utility = -np.inf\n",
        "            for item in candidate:  # candidate items\n",
        "\n",
        "\n",
        "                total_score=0\n",
        "                if item in calib_reco: # ignore duplicate items\n",
        "                    continue\n",
        "\n",
        "                probable_calib = calib_reco + [item]\n",
        "\n",
        "\n",
        "                df_calib =df.loc[tagsdf['movieId'].isin(probable_calib)]\n",
        "\n",
        "                df_calib= df_calib.drop(['Unnamed: 0', 'movieId','title'], axis=1)\n",
        "                for col in df_calib.columns:\n",
        "                  calib_distr[col]=df_calib[col].sum()\n",
        "                calib_distr= {k: v / total for total in (sum(calib_distr.values()),) for k, v in calib_distr.items()}\n",
        "\n",
        "                k= len(calib_distr.keys())\n",
        "                for emotion, score in calib_distr.items():\n",
        "                        normalize_emotions = round(score /(k) , 3)\n",
        "                        calib_distr[emotion] = normalize_emotions\n",
        "\n",
        "                st = set(probable_calib)\n",
        "                indexes= ([i for i, e in enumerate(test_items) if e in st])\n",
        "\n",
        "                #indexes=[i for i, val in enumerate(test_items) if val in probable_calib]\n",
        "\n",
        "                scores=[]\n",
        "                for i in indexes:\n",
        "\n",
        "                  scores.append(predicted_labels[i])\n",
        "                total_score= sum(scores)\n",
        "\n",
        "                #print(\"total_score\", total_score)\n",
        "\n",
        "                utility = self.compute_utility(calib_distr,interacted_distr,total_score,lmbda) # add item to best_item if increase utility of calib_reco\n",
        "                if utility > max_utility:\n",
        "                    max_utility = utility\n",
        "                    best_item = item\n",
        "            calib_reco.append(best_item)\n",
        "\n",
        "        df_calib =df.loc[df['movieId'].isin(calib_reco)]\n",
        "\n",
        "        df_calib= df_calib.drop(['Unnamed: 0', 'movieId','title'], axis=1)\n",
        "        distr_eval={}\n",
        "        for col in df_calib.columns:\n",
        "          distr_eval[col]=df_calib[col].sum()\n",
        "        distr_eval= {k: v / total for total in (sum(distr_eval.values()),) for k, v in distr_eval.items()}\n",
        "\n",
        "        k= len(distr_eval.keys())\n",
        "        for emotion, score in distr_eval.items():\n",
        "                normalize_emotions = round(score /(k) , 3)\n",
        "                distr_eval[emotion] = normalize_emotions\n",
        "        #KLD= compute_kl_divergence(interacted_distr,distr_eval)\n",
        "\n",
        "        sum_score=0\n",
        "\n",
        "        list_hit=[]\n",
        "        for i in calib_reco:\n",
        "          if i in validation_dict:\n",
        "            list_hit.append(i)\n",
        "        st = set(list_hit)\n",
        "        indexes= ([i for i, e in enumerate(test_items) if e in st])\n",
        "        for j in indexes:\n",
        "          sum_score+= predicted_labels[j]\n",
        "\n",
        "\n",
        "        KLD= self.compute_kl_divergence(interacted_distr,distr_eval)\n",
        "        new_KLD= self.kl_divergence(KLD_val,KLD)\n",
        "\n",
        "\n",
        "\n",
        "        MMR= ((1-lmbda)*sum_score) + (lmbda*new_KLD )\n",
        "\n",
        "        if MMR>max:\n",
        "          Best_lmbda=lmbda\n",
        "          max=MMR\n",
        "          print(\"Best\",Best_lmbda)\n",
        "      return  Best_lmbda\n",
        "\n",
        "\n",
        "\n",
        "  def calibrated_final_list(self,candidate_items,test_items,predicted_labels,rows,interacted_distr,df,val_distr,validation_dict,KLD_val):\n",
        "\n",
        "    calibrated_recommendations={}\n",
        "    custom= variance(rows,interacted_distr)\n",
        "    landa_best={}\n",
        "    #landa_list=[0,0.3,0.5,0.8,0.9]\n",
        "    for user_id in rows:\n",
        "       print('user',user_id)\n",
        "\n",
        "\n",
        "       landa_best[user_id]=self.calib_recommend(candidate_items[user_id], interacted_distr[user_id],test_items[user_id],predicted_labels[user_id],df,custom[user_id],val_distr[user_id],validation_dict[user_id],KLD_val[user_id])\n",
        "\n",
        "    return landa_best\n",
        "\n",
        "\n",
        "CalibratedList = CalibratedListProduction(15)\n",
        "#rows= conversion(finall_test_rows,finall_test)\n",
        "\n",
        "\n",
        "my_landa =CalibratedList.calibrated_final_list(candidate_items,test_items ,predicted_labels,rows,interacted_distr,df,val_distr,validation_dict,KLD_val)\n",
        "print(\"completed\")\n",
        "\"\"\"a_file = open(\"/content/gdrive/MyDrive/final_calibrated_list_kaggle_val_genre.pkl\", \"wb\")\n",
        "pickle.dump(final_calibrated_list_kaggle, a_file)\n",
        "a_file.close()\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yv9cHO93WfI"
      },
      "source": [
        "\n",
        "#!!!!!!!!!!!!!!!!!\n",
        "\n",
        "\n",
        "#fisrt idea\n",
        "\n",
        "class CalibratedListProduction():\n",
        "  def __init__(self,topn):\n",
        "\n",
        "    self.topn=topn\n",
        "\n",
        "\n",
        "\n",
        "  def compute_kl_divergence(self,interacted_distr, reco_distr, alpha=0.01):\n",
        "      kl_div = 0.\n",
        "      for emotion, score in interacted_distr.items():\n",
        "          reco_score = reco_distr.get(emotion, 0.)\n",
        "          if score==0 and reco_score==0:\n",
        "            kl_div+=0\n",
        "          else:\n",
        "             if score!=0:\n",
        "              reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "              kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "      return kl_div\n",
        "  def kl_divergence(self,p, q):\n",
        "    return (p * np.log2(p/q))\n",
        "    #for i in range(len(p)))\n",
        "\n",
        "\n",
        "  def js_divergence(self,p, q):\n",
        "    m = 0.5 * (p + q)\n",
        "    return 0.5 * kl_divergence(p, m) + 0.5 * kl_divergence(q, m)\n",
        "\n",
        "  def compute_utility(self,reco_distr, interacted_distr,total_score,lmbda):\n",
        "      \"\"\"\n",
        "      Our objective function for computing the utility score for\n",
        "      the list of recommended items.\n",
        "\n",
        "      lmbda : float, 0.0 ~ 1.0, default 0.5\n",
        "          Lambda term controls the score and calibration tradeoff,\n",
        "          the higher the lambda the higher the resulting recommendation\n",
        "          will be calibrated. Lambda is keyword in Python, so it's\n",
        "          lmbda instead ^^\n",
        "      \"\"\"\n",
        "\n",
        "      kl_div = self.compute_kl_divergence(interacted_distr,reco_distr)\n",
        "\n",
        "      # kl divergence is the lower the better, while score is\n",
        "      # the higher the better so remember to negate it in the calculation\n",
        "      utility = (1 - lmbda) * total_score - lmbda * kl_div\n",
        "      return utility\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def calib_recommend(self,candidate,interacted_distr,test_items,predicted_labels,tagsdf,custom,val_distr,validation_dict,KLD_val):\n",
        "\n",
        "      \"\"\"\n",
        "      start with an empty recommendation list,\n",
        "      loop over the topn cardinality, during each iteration\n",
        "      update the list with the item that maximizes the utility function.\n",
        "      \"\"\"\n",
        "      final_calibration_list=[]\n",
        "      calib_distr={}\n",
        "      max=-np.inf\n",
        "      Best_lmbda=0\n",
        "      for lmbda in [0,0.3,0.5,0.8,0.9]:\n",
        "        calib_reco=[]\n",
        "        for _ in range(self.topn):\n",
        "            max_utility = -np.inf\n",
        "            for item in candidate:  # candidate items\n",
        "\n",
        "\n",
        "                total_score=0\n",
        "                if item in calib_reco: # ignore duplicate items\n",
        "                    continue\n",
        "\n",
        "                probable_calib = calib_reco + [item]\n",
        "\n",
        "\n",
        "                df_calib =tagsdf.loc[tagsdf['movieId'].isin(probable_calib)]\n",
        "\n",
        "                df_calib= df_calib.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "                for col in df_calib.columns:\n",
        "                  calib_distr[col]=df_calib[col].sum()\n",
        "                calib_distr= {k: v / total for total in (sum(calib_distr.values()),) for k, v in calib_distr.items()}\n",
        "\n",
        "                k= len(calib_distr.keys())\n",
        "                for emotion, score in calib_distr.items():\n",
        "                        normalize_emotions = round(score /(k) , 3)\n",
        "                        calib_distr[emotion] = normalize_emotions\n",
        "\n",
        "                st = set(probable_calib)\n",
        "                indexes= ([i for i, e in enumerate(test_items) if e in st])\n",
        "\n",
        "                #indexes=[i for i, val in enumerate(test_items) if val in probable_calib]\n",
        "\n",
        "                scores=[]\n",
        "                for i in indexes:\n",
        "\n",
        "                  scores.append(predicted_labels[i])\n",
        "                total_score= sum(scores)\n",
        "\n",
        "                #print(\"total_score\", total_score)\n",
        "\n",
        "                utility = self.compute_utility(calib_distr,interacted_distr,total_score,lmbda) # add item to best_item if increase utility of calib_reco\n",
        "                if utility > max_utility:\n",
        "                    max_utility = utility\n",
        "                    best_item = item\n",
        "            calib_reco.append(best_item)\n",
        "\n",
        "        df_calib =tagsdf.loc[tagsdf['movieId'].isin(calib_reco)]\n",
        "\n",
        "        df_calib= df_calib.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "        distr_eval={}\n",
        "        for col in df_calib.columns:\n",
        "          distr_eval[col]=df_calib[col].sum()\n",
        "        distr_eval= {k: v / total for total in (sum(distr_eval.values()),) for k, v in distr_eval.items()}\n",
        "\n",
        "        k= len(distr_eval.keys())\n",
        "        for emotion, score in distr_eval.items():\n",
        "                normalize_emotions = round(score /(k) , 3)\n",
        "                distr_eval[emotion] = normalize_emotions\n",
        "        #KLD= compute_kl_divergence(interacted_distr,distr_eval)\n",
        "\n",
        "        sum_score=0\n",
        "\n",
        "        list_hit=[]\n",
        "        for i in calib_reco:\n",
        "          if i in validation_dict:\n",
        "            list_hit.append(i)\n",
        "        st = set(list_hit)\n",
        "        indexes= ([i for i, e in enumerate(test_items) if e in st])\n",
        "        for j in indexes:\n",
        "          sum_score+= predicted_labels[j]\n",
        "\n",
        "\n",
        "        KLD= self.compute_kl_divergence(interacted_distr,distr_eval)\n",
        "        new_KLD= self.kl_divergence(KLD_val,KLD)\n",
        "\n",
        "\n",
        "\n",
        "        MMR= ((1-lmbda)*sum_score) + (lmbda*new_KLD )\n",
        "\n",
        "        if MMR>max:\n",
        "          Best_lmbda=lmbda\n",
        "          max=MMR\n",
        "          print(\"Best\",Best_lmbda)\n",
        "      return  Best_lmbda\n",
        "\n",
        "\n",
        "\n",
        "  def calibrated_final_list(self,candidate_items,test_items,predicted_labels,rows,interacted_distr,tagsdf,val_distr,validation_dict,KLD_val):\n",
        "\n",
        "    calibrated_recommendations={}\n",
        "    custom= variance(rows,interacted_distr)\n",
        "    landa_best={}\n",
        "    #landa_list=[0,0.3,0.5,0.8,0.9]\n",
        "    for user_id in rows:\n",
        "       print('user',user_id)\n",
        "\n",
        "\n",
        "       landa_best[user_id]=self.calib_recommend(candidate_items[user_id], interacted_distr[user_id],test_items[user_id],predicted_labels[user_id],tagsdf,custom[user_id],val_distr[user_id],validation_dict[user_id],KLD_val[user_id])\n",
        "\n",
        "    return landa_best\n",
        "\n",
        "\n",
        "CalibratedList = CalibratedListProduction(15)\n",
        "#rows= conversion(finall_test_rows,finall_test)\n",
        "\n",
        "\n",
        "my_landa =CalibratedList.calibrated_final_list(candidate_items,test_items ,predicted_labels,rows,interacted_distr,tagsdf,val_distr,validation_dict,KLD_val)\n",
        "print(\"completed\")\n",
        "\"\"\"a_file = open(\"/content/gdrive/MyDrive/final_calibrated_list_kaggle_0.8_smallest.pkl\", \"wb\")\n",
        "pickle.dump(final_calibrated_list_kaggle, a_file)\n",
        "a_file.close()\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr84dmimCNvz"
      },
      "source": [
        "a_file = open(\"/content/gdrive/MyDrive/landa.pkl\", \"wb\")\n",
        "pickle.dump(my_landa, a_file)\n",
        "a_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phg4fUXMgXQ7"
      },
      "source": [
        "\n",
        "#!!!!!!!!!!!!!!!!!\n",
        "\n",
        "class CalibratedListProduction():\n",
        "  def __init__(self,topn):\n",
        "\n",
        "    self.topn=topn\n",
        "\n",
        "\n",
        "\n",
        "  def compute_kl_divergence(self,interacted_distr, reco_distr, alpha=0.01):\n",
        "      kl_div = 0.\n",
        "      for emotion, score in interacted_distr.items():\n",
        "          reco_score = reco_distr.get(emotion, 0.)\n",
        "          if score==0 and reco_score==0:\n",
        "            kl_div+=0\n",
        "          else:\n",
        "             if score!=0:\n",
        "              reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "              kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "      return kl_div\n",
        "  def kl_divergence(p, q):\n",
        "    return sum(p[i] * log2(p[i]/q[i]) for i in range(len(p)))\n",
        "\n",
        "\n",
        "  def js_divergence(self,p, q):\n",
        "    m = 0.5 * (p + q)\n",
        "    return 0.5 * kl_divergence(p, m) + 0.5 * kl_divergence(q, m)\n",
        "\n",
        "  def compute_utility(self,reco_distr, interacted_distr,total_score,lmbda):\n",
        "      \"\"\"\n",
        "      Our objective function for computing the utility score for\n",
        "      the list of recommended items.\n",
        "\n",
        "      lmbda : float, 0.0 ~ 1.0, default 0.5\n",
        "          Lambda term controls the score and calibration tradeoff,\n",
        "          the higher the lambda the higher the resulting recommendation\n",
        "          will be calibrated. Lambda is keyword in Python, so it's\n",
        "          lmbda instead ^^\n",
        "      \"\"\"\n",
        "\n",
        "      kl_div = self.compute_kl_divergence(interacted_distr,reco_distr)\n",
        "\n",
        "      # kl divergence is the lower the better, while score is\n",
        "      # the higher the better so remember to negate it in the calculation\n",
        "      utility = (1 - lmbda) * total_score - lmbda * kl_div\n",
        "      return utility\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def calib_recommend(self,candidate,interacted_distr,test_items,predicted_labels,tagsdf,custom,val_distr,validation_dict):\n",
        "\n",
        "      \"\"\"\n",
        "      start with an empty recommendation list,\n",
        "      loop over the topn cardinality, during each iteration\n",
        "      update the list with the item that maximizes the utility function.\n",
        "      \"\"\"\n",
        "      final_calibration_list=[]\n",
        "      calib_distr={}\n",
        "      max=-np.inf\n",
        "      Best_lmbda=0\n",
        "      for lmbda in [0,0.3,0.5,0.8,0.9]:\n",
        "        calib_reco=[]\n",
        "        for _ in range(self.topn):\n",
        "            max_utility = -np.inf\n",
        "            for item in candidate:  # candidate items\n",
        "\n",
        "\n",
        "                total_score=0\n",
        "                if item in calib_reco: # ignore duplicate items\n",
        "                    continue\n",
        "\n",
        "                probable_calib = calib_reco + [item]\n",
        "\n",
        "\n",
        "                df_calib =tagsdf.loc[tagsdf['movieId'].isin(probable_calib)]\n",
        "\n",
        "                df_calib= df_calib.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "                for col in df_calib.columns:\n",
        "                  calib_distr[col]=df_calib[col].sum()\n",
        "                calib_distr= {k: v / total for total in (sum(calib_distr.values()),) for k, v in calib_distr.items()}\n",
        "\n",
        "                k= len(calib_distr.keys())\n",
        "                for emotion, score in calib_distr.items():\n",
        "                        normalize_emotions = round(score /(k) , 3)\n",
        "                        calib_distr[emotion] = normalize_emotions\n",
        "\n",
        "                st = set(probable_calib)\n",
        "                indexes= ([i for i, e in enumerate(test_items) if e in st])\n",
        "\n",
        "                #indexes=[i for i, val in enumerate(test_items) if val in probable_calib]\n",
        "\n",
        "                scores=[]\n",
        "                for i in indexes:\n",
        "\n",
        "                  scores.append(predicted_labels[i])\n",
        "                total_score= sum(scores)\n",
        "\n",
        "                #print(\"total_score\", total_score)\n",
        "\n",
        "                utility = self.compute_utility(calib_distr,interacted_distr,total_score,lmbda) # add item to best_item if increase utility of calib_reco\n",
        "                if utility > max_utility:\n",
        "                    max_utility = utility\n",
        "                    best_item = item\n",
        "            calib_reco.append(best_item)\n",
        "\n",
        "        df_calib =tagsdf.loc[tagsdf['movieId'].isin(calib_reco)]\n",
        "\n",
        "        df_calib= df_calib.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "        distr_eval={}\n",
        "        for col in df_calib.columns:\n",
        "          distr_eval[col]=df_calib[col].sum()\n",
        "        distr_eval= {k: v / total for total in (sum(distr_eval.values()),) for k, v in distr_eval.items()}\n",
        "\n",
        "        k= len(distr_eval.keys())\n",
        "        for emotion, score in distr_eval.items():\n",
        "                normalize_emotions = round(score /(k) , 3)\n",
        "                distr_eval[emotion] = normalize_emotions\n",
        "        #KLD= compute_kl_divergence(interacted_distr,distr_eval)\n",
        "\n",
        "        sum_score=0\n",
        "        print(calib_reco, \"for this\", lmbda)\n",
        "        print(validation_dict)\n",
        "        list_hit=[]\n",
        "        for i in calib_reco:\n",
        "          if i in validation_dict:\n",
        "            list_hit.append(i)\n",
        "        st = set(list_hit)\n",
        "        indexes= ([i for i, e in enumerate(test_items) if e in st])\n",
        "        for j in indexes:\n",
        "          sum_score+= predicted_labels[j]\n",
        "\n",
        "        print(\"sum\", sum_score)\n",
        "\n",
        "        KLD= self.compute_kl_divergence(val_distr,distr_eval)\n",
        "        print(\"KLD\",KLD)\n",
        "\n",
        "        MMR= ((1-lmbda)*sum_score) + (lmbda*KLD )\n",
        "\n",
        "        if MMR>max:\n",
        "          Best_lmbda=lmbda\n",
        "          max=MMR\n",
        "          print(\"Best\",Best_lmbda)\n",
        "      return  Best_lmbda\n",
        "\n",
        "\n",
        "\n",
        "  def calibrated_final_list(self,candidate_items,test_items,predicted_labels,rows,interacted_distr,tagsdf,val_distr,validation_dict):\n",
        "\n",
        "    calibrated_recommendations={}\n",
        "    custom= variance(rows,interacted_distr)\n",
        "    landa_best={}\n",
        "    #landa_list=[0,0.3,0.5,0.8,0.9]\n",
        "    for user_id in rows:\n",
        "       print('user',user_id)\n",
        "\n",
        "\n",
        "       landa_best[user_id]=self.calib_recommend(candidate_items[user_id], interacted_distr[user_id],test_items[user_id],predicted_labels[user_id],tagsdf,custom[user_id],val_distr[user_id],validation_dict[user_id])\n",
        "\n",
        "    return landa_best\n",
        "\n",
        "\n",
        "CalibratedList = CalibratedListProduction(15)\n",
        "#rows= conversion(finall_test_rows,finall_test)\n",
        "\n",
        "\n",
        "my_landa =CalibratedList.calibrated_final_list(candidate_items,test_items ,predicted_labels,rows,interacted_distr,tagsdf,val_distr,validation_dict)\n",
        "print(\"completed\")\n",
        "\"\"\"a_file = open(\"/content/gdrive/MyDrive/final_calibrated_list_kaggle_0.8_smallest.pkl\", \"wb\")\n",
        "pickle.dump(final_calibrated_list_kaggle, a_file)\n",
        "a_file.close()\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzwebL_D1-j1",
        "outputId": "c52b302a-21de-4e89-dbde-c73e32a1c1c1"
      },
      "source": [
        "def compute_kl_divergence(interacted_distr, reco_distr, alpha=0.01):\n",
        "    kl_div = 0.\n",
        "    for emotion, score in interacted_distr.items():\n",
        "        reco_score = reco_distr.get(emotion, 0.)\n",
        "\n",
        "        if score==0 and reco_score==0:\n",
        "          kl_div+=0\n",
        "        else:\n",
        "          reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "          if score!=0:\n",
        "            kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "    return kl_div\n",
        "val_distr ={'Happy': 0.012, 'Angry': 0.0, 'Surprise': 0.054, 'Sad': 0.0, 'Fear': 0.134}\n",
        "distr_eval= {'Happy': 0.04, 'Angry': 0.009, 'Surprise': 0.031, 'Sad': 0.037, 'Fear': 0.083}\n",
        "compute_kl_divergence(val_distr,distr_eval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1133559001274367"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWs_Exju5w1b"
      },
      "source": [
        "##### Test Our Idea\n",
        "#with test data\n",
        "class CalibratedListProduction():\n",
        "  def __init__(self,topn):\n",
        "\n",
        "    self.topn=topn\n",
        "\n",
        "\n",
        "\n",
        "  def compute_kl_divergence(self,interacted_distr, reco_distr, alpha=0.01):\n",
        "      kl_div = 0.\n",
        "      for emotion, score in interacted_distr.items():\n",
        "          reco_score = reco_distr.get(emotion, 0.)\n",
        "          if score==0 and reco_score==0:\n",
        "            kl_div+=0\n",
        "          else:\n",
        "            reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "            kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "      return kl_div\n",
        "\n",
        "\n",
        "\n",
        "  def compute_utility(self,reco_distr, interacted_distr,total_score,lmbda):\n",
        "      \"\"\"\n",
        "      Our objective function for computing the utility score for\n",
        "      the list of recommended items.\n",
        "\n",
        "      lmbda : float, 0.0 ~ 1.0, default 0.5\n",
        "          Lambda term controls the score and calibration tradeoff,\n",
        "          the higher the lambda the higher the resulting recommendation\n",
        "          will be calibrated. Lambda is keyword in Python, so it's\n",
        "          lmbda instead ^^\n",
        "      \"\"\"\n",
        "\n",
        "      kl_div = self.compute_kl_divergence(interacted_distr,reco_distr)\n",
        "\n",
        "      # kl divergence is the lower the better, while score is\n",
        "      # the higher the better so remember to negate it in the calculation\n",
        "      utility = (1 - lmbda) * total_score - lmbda * kl_div\n",
        "      return utility\n",
        "\n",
        "\n",
        "  def compute_utility_new(self,reco_distr, interacted_distr,total_score,lmbda):\n",
        "      \"\"\"\n",
        "      Our objective function for computing the utility score for\n",
        "      the list of recommended items.\n",
        "\n",
        "      lmbda : float, 0.0 ~ 1.0, default 0.5\n",
        "          Lambda term controls the score and calibration tradeoff,\n",
        "          the higher the lambda the higher the resulting recommendation\n",
        "          will be calibrated. Lambda is keyword in Python, so it's\n",
        "          lmbda instead ^^\n",
        "      \"\"\"\n",
        "\n",
        "      kl_div = self.compute_kl_divergence(interacted_distr,reco_distr)\n",
        "\n",
        "      # kl divergence is the lower the better, while score is\n",
        "      # the higher the better so remember to negate it in the calculation\n",
        "      utility = (1 - lmbda) * total_score - lmbda * kl_div\n",
        "      return utility,kl_div\n",
        "\n",
        "\n",
        "  def calib_recommend(self,candidate,interacted_distr,test_items,predicted_labels,tagsdf,lmbda):\n",
        "\n",
        "      \"\"\"\n",
        "      start with an empty recommendation list,\n",
        "      loop over the topn cardinality, during each iteration\n",
        "      update the list with the item that maximizes the utility function.\n",
        "      \"\"\"\n",
        "      final_calibration_list=[]\n",
        "      calib_distr={}\n",
        "      calib_reco=[]\n",
        "      for _ in range(self.topn):\n",
        "          max_utility = -np.inf\n",
        "          for item in candidate:  # candidate items\n",
        "\n",
        "\n",
        "              total_score=0\n",
        "              if item in calib_reco: # ignore duplicate items\n",
        "                  continue\n",
        "\n",
        "              probable_calib = calib_reco + [item]\n",
        "\n",
        "\n",
        "              df_calib =tagsdf.loc[tagsdf['movieId'].isin(probable_calib)]\n",
        "\n",
        "              df_calib= df_calib.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "              for col in df_calib.columns:\n",
        "                calib_distr[col]=df_calib[col].sum()\n",
        "              calib_distr= {k: v / total for total in (sum(calib_distr.values()),) for k, v in calib_distr.items()}\n",
        "\n",
        "              k= len(calib_distr.keys())\n",
        "              for emotion, score in calib_distr.items():\n",
        "                      normalize_emotions = round(score /(k) , 3)\n",
        "                      calib_distr[emotion] = normalize_emotions\n",
        "\n",
        "              st = set(probable_calib)\n",
        "              indexes= ([i for i, e in enumerate(test_items) if e in st])\n",
        "\n",
        "              #indexes=[i for i, val in enumerate(test_items) if val in probable_calib]\n",
        "\n",
        "              scores=[]\n",
        "              for i in indexes:\n",
        "\n",
        "                scores.append(predicted_labels[i])\n",
        "              total_score= sum(scores)\n",
        "\n",
        "              #print(\"total_score\", total_score)\n",
        "\n",
        "              utility = self.compute_utility(calib_distr,interacted_distr,total_score,lmbda) # add item to best_item if increase utility of calib_reco\n",
        "              if utility > max_utility:\n",
        "                  max_utility = utility\n",
        "                  best_item = item\n",
        "          calib_reco.append(best_item)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      return calib_reco\n",
        "\n",
        "\n",
        "\n",
        "  def calibrated_final_list(self,candidate_items,test_items,predicted_labels,rows,interacted_distr,tagsdf,my_landa):\n",
        "\n",
        "    calibrated_recommendations={}\n",
        "\n",
        "\n",
        "    #landa_list=[0,0.3,0.5,0.8,0.9]\n",
        "    for user_id in rows:\n",
        "\n",
        "      if user_id in interacted_distr.keys() & test_items.keys():\n",
        "       calibrated_recommendations[user_id]=self.calib_recommend(candidate_items[user_id], interacted_distr[user_id],test_items[user_id],predicted_labels[user_id],tagsdf,my_landa[user_id])\n",
        "\n",
        "    return calibrated_recommendations\n",
        "\n",
        "\n",
        "CalibratedList = CalibratedListProduction(20)\n",
        "#rows= conversion(finall_test_rows,finall_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "final_calibrated_list_kaggle =CalibratedList.calibrated_final_list(candidate_items,test_items ,predicted_labels,rows,interacted_distr,tagsdf,my_landa)\n",
        "print(\"completed\")\n",
        "\"\"\"a_file = open(\"/content/gdrive/MyDrive/final_calibrated_list_kaggle_0.8_smallest.pkl\", \"wb\")\n",
        "pickle.dump(final_calibrated_list_kaggle, a_file)\n",
        "a_file.close()\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QIhwquQt1LO"
      },
      "source": [
        "df=pd.read_csv(\"/content/gdrive/MyDrive/df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6ydgPjX5cjT"
      },
      "source": [
        "df1=df.drop(['Unnamed: 0','title'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phz_tBPAx-ev"
      },
      "source": [
        "df1.set_index(\"movieId\", drop=True, inplace=True)\n",
        "dictionary = df1.to_dict(orient=\"index\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgQao3PU9U6M"
      },
      "source": [
        "predict_list=[54286,55069]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1e8vUO36h00"
      },
      "source": [
        "new_dictionary={}\n",
        "for key,value in dictionary.items():\n",
        "  if key in predict_list:\n",
        "    new_dictionary[key]=value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV-rT2OBTCdJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfYqfckN_Jza"
      },
      "source": [
        "from collections import Counter\n",
        "h=sum((Counter(d) for d in new_dictionary.values()), Counter())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsvMQU9rA_Xk"
      },
      "source": [
        "calib_distr= {k: v / total for total in (sum(h.values()),) for k, v in h.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY_dOgxdDBel"
      },
      "source": [
        "\n",
        "new_dictionary=sum((Counter(d) for d in new_dictionary.values()), Counter())\n",
        "new_dictionary= {k: v / total for total in (sum(new_dictionary.values()),) for k, v in new_dictionary.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzFlF4qsFu9A",
        "outputId": "f36e4738-a2f2-463f-99e6-080471bc03ba"
      },
      "source": [
        "new_dictionary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Action': 0.16666666666666666,\n",
              " 'Crime': 0.16666666666666666,\n",
              " 'Drama': 0.5,\n",
              " 'Thriller': 0.16666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChmRl6ohSyfP"
      },
      "source": [
        "z={k:dictionary[k] for k in predict_list if k in dictionary}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0D7UEFKHa7s"
      },
      "source": [
        "a_file = open(\"/content/gdrive/MyDrive/landa_genre.pkl\", \"rb\")\n",
        "my_landa= pickle.load(a_file)\n",
        "a_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zIrsoVaH0wf"
      },
      "source": [
        "rows=my_landa.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fC2HrsHJast",
        "outputId": "28801d4a-1f2f-4d3e-f0dc-87f614a02270"
      },
      "source": [
        "##### Test Our Idea\n",
        "#with test data.   #ganres # genres\n",
        "from collections import Counter\n",
        "class CalibratedListProduction():\n",
        "  def __init__(self,topn):\n",
        "\n",
        "    self.topn=topn\n",
        "\n",
        "\n",
        "  def compute_kl_divergence(self,interacted_distr, reco_distr, alpha=0.01):\n",
        "      kl_div = 0.\n",
        "      for emotion, score in interacted_distr.items():\n",
        "          reco_score = reco_distr.get(emotion, 0.)\n",
        "          if score==0 and reco_score==0:\n",
        "            kl_div+=0\n",
        "          else:\n",
        "\n",
        "            reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "            if score!=0:\n",
        "              kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "\n",
        "      return kl_div\n",
        "\n",
        "\n",
        "\n",
        "  def compute_utility(self,reco_distr, interacted_distr,total_score,lmbda):\n",
        "      \"\"\"\n",
        "      Our objective function for computing the utility score for\n",
        "      the list of recommended items.\n",
        "\n",
        "      lmbda : float, 0.0 ~ 1.0, default 0.5\n",
        "          Lambda term controls the score and calibration tradeoff,\n",
        "          the higher the lambda the higher the resulting recommendation\n",
        "          will be calibrated. Lambda is keyword in Python, so it's\n",
        "          lmbda instead ^^\n",
        "      \"\"\"\n",
        "\n",
        "      kl_div = self.compute_kl_divergence(interacted_distr,reco_distr)\n",
        "\n",
        "\n",
        "      # kl divergence is the lower the better, while score is\n",
        "      # the higher the better so remember to negate it in the calculation\n",
        "      utility = (1 - lmbda) * total_score - lmbda * kl_div\n",
        "      return utility\n",
        "\n",
        "\n",
        "  def compute_utility_new(self,reco_distr, interacted_distr,total_score,lmbda):\n",
        "      \"\"\"\n",
        "      Our objective function for computing the utility score for\n",
        "      the list of recommended items.\n",
        "\n",
        "      lmbda : float, 0.0 ~ 1.0, default 0.5\n",
        "          Lambda term controls the score and calibration tradeoff,\n",
        "          the higher the lambda the higher the resulting recommendation\n",
        "          will be calibrated. Lambda is keyword in Python, so it's\n",
        "          lmbda instead ^^\n",
        "      \"\"\"\n",
        "\n",
        "      kl_div = self.compute_kl_divergence(interacted_distr,reco_distr)\n",
        "\n",
        "      # kl divergence is the lower the better, while score is\n",
        "      # the higher the better so remember to negate it in the calculation\n",
        "      utility = (1 - lmbda) * total_score - lmbda * kl_div\n",
        "      return utility,kl_div\n",
        "\n",
        "\n",
        "  def calib_recommend(self,candidate,interacted_distr,test_items,predicted_labels,dictionary,lmbda):\n",
        "\n",
        "      \"\"\"\n",
        "      start with an empty recommendation list,\n",
        "      loop over the topn cardinality, during each iteration\n",
        "      update the list with the item that maximizes the utility function.\n",
        "      \"\"\"\n",
        "      final_calibration_list=[]\n",
        "      calib_distr={}\n",
        "      calib_reco=[]\n",
        "      v={}\n",
        "      for _ in range(self.topn):\n",
        "          max_utility = -np.inf\n",
        "          for item in candidate:  # candidate items\n",
        "\n",
        "\n",
        "              total_score=0\n",
        "              if item in calib_reco: # ignore duplicate items\n",
        "                  continue\n",
        "\n",
        "              probable_calib = calib_reco + [item]\n",
        "\n",
        "\n",
        "              calib_distr={k:dictionary[k] for k in probable_calib if k in dictionary}\n",
        "\n",
        "              h=sum((Counter(d) for d in calib_distr.values()), Counter())\n",
        "              v= {k: v / total for total in (sum(h.values()),) for k, v in h.items()}\n",
        "\n",
        "              k= len(v.keys())\n",
        "              for emotion, score in v.items():\n",
        "                      normalize_emotions = round(score /(k) , 3)\n",
        "                      v[emotion] = normalize_emotions\n",
        "\n",
        "              st = set(probable_calib)\n",
        "\n",
        "              indexes= ([i for i, e in enumerate(test_items) if e in st])\n",
        "\n",
        "              #indexes=[i for i, val in enumerate(test_items) if val in probable_calib]\n",
        "\n",
        "              scores=[]\n",
        "              for i in indexes:\n",
        "\n",
        "                scores.append(predicted_labels[i])\n",
        "              total_score= sum(scores)\n",
        "\n",
        "\n",
        "              #print(\"total_score\", total_score)\n",
        "\n",
        "              utility = self.compute_utility(v,interacted_distr,total_score,lmbda) # add item to best_item if increase utility of calib_reco\n",
        "\n",
        "              if utility > max_utility:\n",
        "\n",
        "                  max_utility = utility\n",
        "                  best_item = item\n",
        "\n",
        "          calib_reco.append(best_item)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      return calib_reco\n",
        "\n",
        "\n",
        "\n",
        "  def calibrated_final_list(self,candidate_items,test_items,predicted_labels,rows,interacted_distr,dictionary,my_landa):\n",
        "\n",
        "    calibrated_recommendations={}\n",
        "\n",
        "\n",
        "    #landa_list=[0,0.3,0.5,0.8,0.9]\n",
        "    for user_id in rows:\n",
        "\n",
        "      if user_id in interacted_distr.keys() & test_items.keys():\n",
        "       calibrated_recommendations[user_id]=self.calib_recommend(candidate_items[user_id], interacted_distr[user_id],test_items[user_id],predicted_labels[user_id],dictionary,my_landa[user_id])\n",
        "\n",
        "    return calibrated_recommendations\n",
        "\n",
        "\n",
        "CalibratedList = CalibratedListProduction(20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "final_calibrated_list_kaggle =CalibratedList.calibrated_final_list(candidate_items,test_items ,predicted_labels,rows,interacted_distr,dictionary,my_landa)\n",
        "print(\"completed\")\n",
        "a_file = open(\"/content/gdrive/MyDrive/final_calibrated_list_kaggle_genre.pkl\", \"wb\")\n",
        "pickle.dump(final_calibrated_list_kaggle, a_file)\n",
        "a_file.close()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el35_t1IcjeK",
        "outputId": "0334e379-b7e7-4455-d8e4-246d9b13b461"
      },
      "source": [
        "##### Test Our Idea\n",
        "#with test data.   #ganres # genres  # variance\n",
        "from collections import Counter\n",
        "class CalibratedListProduction():\n",
        "  def __init__(self,topn):\n",
        "\n",
        "    self.topn=topn\n",
        "\n",
        "\n",
        "  def compute_kl_divergence(self,interacted_distr, reco_distr, alpha=0.01):\n",
        "      kl_div = 0.\n",
        "      for emotion, score in interacted_distr.items():\n",
        "          reco_score = reco_distr.get(emotion, 0.)\n",
        "          if score==0 and reco_score==0:\n",
        "            kl_div+=0\n",
        "          else:\n",
        "\n",
        "            reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "            if score!=0:\n",
        "              kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "\n",
        "      return kl_div\n",
        "\n",
        "\n",
        "\n",
        "  def compute_utility(self,reco_distr, interacted_distr,total_score,lmbda):\n",
        "      \"\"\"\n",
        "      Our objective function for computing the utility score for\n",
        "      the list of recommended items.\n",
        "\n",
        "      lmbda : float, 0.0 ~ 1.0, default 0.5\n",
        "          Lambda term controls the score and calibration tradeoff,\n",
        "          the higher the lambda the higher the resulting recommendation\n",
        "          will be calibrated. Lambda is keyword in Python, so it's\n",
        "          lmbda instead ^^\n",
        "      \"\"\"\n",
        "\n",
        "      kl_div = self.compute_kl_divergence(interacted_distr,reco_distr)\n",
        "\n",
        "\n",
        "      # kl divergence is the lower the better, while score is\n",
        "      # the higher the better so remember to negate it in the calculation\n",
        "      utility = (1 - lmbda) * total_score - lmbda * kl_div\n",
        "      return utility\n",
        "\n",
        "\n",
        "  def compute_utility_new(self,reco_distr, interacted_distr,total_score,lmbda):\n",
        "      \"\"\"\n",
        "      Our objective function for computing the utility score for\n",
        "      the list of recommended items.\n",
        "\n",
        "      lmbda : float, 0.0 ~ 1.0, default 0.5\n",
        "          Lambda term controls the score and calibration tradeoff,\n",
        "          the higher the lambda the higher the resulting recommendation\n",
        "          will be calibrated. Lambda is keyword in Python, so it's\n",
        "          lmbda instead ^^\n",
        "      \"\"\"\n",
        "\n",
        "      kl_div = self.compute_kl_divergence(interacted_distr,reco_distr)\n",
        "\n",
        "      # kl divergence is the lower the better, while score is\n",
        "      # the higher the better so remember to negate it in the calculation\n",
        "      utility = (1 - lmbda) * total_score - lmbda * kl_div\n",
        "      return utility,kl_div\n",
        "\n",
        "\n",
        "  def calib_recommend(self,candidate,interacted_distr,test_items,predicted_labels,dictionary,lmbda):\n",
        "\n",
        "      \"\"\"\n",
        "      start with an empty recommendation list,\n",
        "      loop over the topn cardinality, during each iteration\n",
        "      update the list with the item that maximizes the utility function.\n",
        "      \"\"\"\n",
        "      final_calibraation_list=[]\n",
        "      calib_distr={}\n",
        "      calib_reco=[]\n",
        "      v={}\n",
        "      for _ in range(self.topn):\n",
        "          max_utility = -np.inf\n",
        "          for item in candidate:  # candidate items\n",
        "\n",
        "\n",
        "              total_score=0\n",
        "              if item in calib_reco: # ignore duplicate items\n",
        "                  continue\n",
        "\n",
        "              probable_calib = calib_reco + [item]\n",
        "\n",
        "\n",
        "              calib_distr={k:dictionary[k] for k in probable_calib if k in dictionary}\n",
        "\n",
        "              h=sum((Counter(d) for d in calib_distr.values()), Counter())\n",
        "              v= {k: v / total for total in (sum(h.values()),) for k, v in h.items()}\n",
        "\n",
        "              k= len(v.keys())\n",
        "              for emotion, score in v.items():\n",
        "                      normalize_emotions = round(score /(k) , 3)\n",
        "                      v[emotion] = normalize_emotions\n",
        "\n",
        "              st = set(probable_calib)\n",
        "\n",
        "              indexes= ([i for i, e in enumerate(test_items) if e in st])\n",
        "\n",
        "              #indexes=[i for i, val in enumerate(test_items) if val in probable_calib]\n",
        "\n",
        "              scores=[]\n",
        "              for i in indexes:\n",
        "\n",
        "                scores.append(predicted_labels[i])\n",
        "              total_score= sum(scores)\n",
        "\n",
        "\n",
        "              #print(\"total_score\", total_score)\n",
        "\n",
        "              utility = self.compute_utility(v,interacted_distr,total_score,lmbda) # add item to best_item if increase utility of calib_reco\n",
        "\n",
        "              if utility > max_utility:\n",
        "\n",
        "                  max_utility = utility\n",
        "                  best_item = item\n",
        "\n",
        "          calib_reco.append(best_item)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      return calib_reco\n",
        "\n",
        "\n",
        "\n",
        "  def calibrated_final_list(self,candidate_items,test_items,predicted_labels,rows,interacted_distr,dictionary,custom):\n",
        "\n",
        "    calibrated_recommendations={}\n",
        "\n",
        "\n",
        "    #landa_list=[0,0.3,0.5,0.8,0.9]\n",
        "    for user_id in rows:\n",
        "\n",
        "      if user_id in interacted_distr.keys() & test_items.keys():\n",
        "       calibrated_recommendations[user_id]=self.calib_recommend(candidate_items[user_id], interacted_distr[user_id],test_items[user_id],predicted_labels[user_id],dictionary,custom[user_id])\n",
        "\n",
        "    return calibrated_recommendations\n",
        "\n",
        "\n",
        "CalibratedList = CalibratedListProduction(20)\n",
        "\n",
        "\n",
        "\n",
        "custom=variance(rows,interacted_distr)\n",
        "\n",
        "final_calibrated_list_kaggle =CalibratedList.calibrated_final_list(candidate_items,test_items ,predicted_labels,rows,interacted_distr,dictionary,custom)\n",
        "print(\"completed\")\n",
        "a_file = open(\"/content/gdrive/MyDrive/final_calibrated_list_kaggle_genre_variance.pkl\", \"wb\")\n",
        "pickle.dump(final_calibrated_list_kaggle, a_file)\n",
        "a_file.close()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ukL0MyNmoWg"
      },
      "source": [
        "\n",
        "\n",
        "a_file = open(\"/content/gdrive/MyDrive/final_calibrated_list_kaggle_variance.pkl\", \"rb\")\n",
        "final_calibrated_list_kaggle = pickle.load(a_file)\n",
        "a_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zMzoOeyhdw-",
        "outputId": "6c7ec894-a00f-46bc-f476-2934e3854816"
      },
      "source": [
        "pip install ml_metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ml_metrics\n",
            "  Downloading ml_metrics-0.1.4.tar.gz (5.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ml_metrics) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ml_metrics) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ml_metrics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->ml_metrics) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->ml_metrics) (1.15.0)\n",
            "Building wheels for collected packages: ml-metrics\n",
            "  Building wheel for ml-metrics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-metrics: filename=ml_metrics-0.1.4-py3-none-any.whl size=7845 sha256=4aa40a21649149a3d433ea94538cf2bdc20e19d0c0ed866b270656fb48026d10\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/41/5b/0c6d42b3604a5c823d8922564c4708f84962fa7f2f4facfa6d\n",
            "Successfully built ml-metrics\n",
            "Installing collected packages: ml-metrics\n",
            "Successfully installed ml-metrics-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxYaOPNSofI4"
      },
      "source": [
        "\n",
        "def get_ap_from_list(relevance_array):\n",
        "    relevance_list_size = len(relevance_array)\n",
        "    if relevance_list_size == 0:\n",
        "        return 0.0\n",
        "\n",
        "    relevant = 0\n",
        "    for i in range(relevance_list_size):\n",
        "        if relevance_array[i]:\n",
        "            relevant += 1\n",
        "        return relevant/relevance_list_size\n",
        "\n",
        "def average_precision(test_items, reco_items):\n",
        "    precision=0\n",
        "    # reco_items_df[item_label] = reco_items_df[item_label].astype(str)\n",
        "    for user in reco_items.keys():\n",
        "      vector = [True if x in test_items[user] else False for x in reco_items[user]]\n",
        "\n",
        "      precision+=get_ap_from_list(vector)\n",
        "    return precision/len(reco_items.keys())\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibdUXZqYo5j_",
        "outputId": "d041a969-7568-4651-b289-4b22458e9cc2"
      },
      "source": [
        "average_precision(test_user_item_dict,final_calibrated_list_kaggle)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03775303643724723"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BErgMJ0KsAd3"
      },
      "source": [
        "def precision(actual, predicted, k):\n",
        "    act_set = set(actual)\n",
        "    pred_set = set(predicted)\n",
        "\n",
        "    result = len(act_set & pred_set) / 20\n",
        "    return result\n",
        "\n",
        "def MAP(actual,predicted,k):\n",
        "  total=0\n",
        "\n",
        "  for user in predicted.keys():\n",
        "    #if user in actual.keys():\n",
        "\n",
        "      p= precision(actual[user],predicted[user],k)\n",
        "      total+=p\n",
        "  return total/len(predicted.keys())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrrVWpb6tr3o",
        "outputId": "a74e4299-8811-4b2c-ae64-fd96d3eae27d"
      },
      "source": [
        "print(MAP(test_user_item_dict,final_calibrated_list_kaggle,20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.47682186234817814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVMahyJfzkp0"
      },
      "source": [
        "\n",
        "\n",
        "# i think is not correct but is based on a git code\n",
        "def get_rr_from_list(relevance_array):\n",
        "    relevance_list_size = len(relevance_array)\n",
        "    if relevance_list_size == 0:\n",
        "        return 0.0\n",
        "    for i in range(relevance_list_size):\n",
        "        if relevance_array[i]:\n",
        "            return 1 / (i + 1)\n",
        "    return 0.0\n",
        "\n",
        "\n",
        "def mrr(test_items, reco_items):\n",
        "  precision=0\n",
        "  for user in reco_items.keys():\n",
        "      vector = [True if x in test_items[user] else False for x in reco_items[user]]\n",
        "\n",
        "      precision+=get_rr_from_list(vector)\n",
        "  return precision/(len(reco_items.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pjqO8TpD_TX",
        "outputId": "4b23f580-aded-45c2-a450-521e5f06a335"
      },
      "source": [
        "mrr(test_user_item_dict,final_calibrated_list_kaggle)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7095930163055323"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t_B-czXHn46",
        "outputId": "245f72b1-e0f8-40c8-a396-8ea256865dae"
      },
      "source": [
        "def MRR(reco_items,test_user):\n",
        "  rr_users=0\n",
        "  for user in reco_items.keys():\n",
        "    #if user in test_user.keys():\n",
        "      rr=0\n",
        "      for x in test_user[user]:\n",
        "        if x in reco_items[user]:\n",
        "          rr+=1/(reco_items[user].index(x) +1)\n",
        "      rr_users+=rr/len(reco_items[user])\n",
        "  return rr_users/len(reco_items.keys())\n",
        "\n",
        "\n",
        "\n",
        "MRR(final_calibrated_list_kaggle,test_user_item_dict)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11459666604322756"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-jYvOeSMFUn",
        "outputId": "d252aafc-6308-45df-f238-9ea02dd60582"
      },
      "source": [
        "\n",
        "# show that the result is false for mrr of paper\n",
        "def get_rr_from_list(relevance_array):\n",
        "    relevance_list_size = len(relevance_array)\n",
        "    if relevance_list_size == 0:\n",
        "        return 0.0\n",
        "    for i in range(relevance_list_size):\n",
        "        if relevance_array[i]:\n",
        "            return 1 / (i + 1)\n",
        "    return 0.0\n",
        "\n",
        "zz=[1,2,3,4,5]\n",
        "ww=[2,4,5,1,8]\n",
        "precision = [True if x in ww else False for x in zz]\n",
        "print(precision)\n",
        "print( get_rr_from_list(precision))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[True, True, False, True, True]\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmZDAuoUA3iV"
      },
      "source": [
        "rows= test_user_item_dict.keys() # all test users"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD6GIMfmSJmo"
      },
      "source": [
        "p={'Happy': 0.12192581056193642, 'Angry': 0.03334724539595396, 'Surprise': 0.2555231288475711, 'Sad': 0.25010420486094626, 'Fear': 0.33909961033359226}\n",
        "q= {'Happy': 0.3846153846153846, 'Angry': 0.0, 'Surprise': 0.03678929765886287, 'Sad': 0.060200668896321065, 'Fear': 0.5183946488294314}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D5MurJeVhHF"
      },
      "source": [
        "r=ratings['movieId'].tolist()\n",
        "df= tagsdf['movieId'].tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQhYE_m4-7bj"
      },
      "source": [
        "# MACE\n",
        "\n",
        "\n",
        "# distribution of q\n",
        "\n",
        "def q_distr(list_items):\n",
        "\n",
        "\n",
        "\n",
        "      interacted_distr={}\n",
        "\n",
        "      df_user = tagsdf.loc[tagsdf['movieId'].isin(list_items)]\n",
        "      df_user= df_user.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "\n",
        "      for col in df_user.columns:\n",
        "        interacted_distr[col]=(df_user[col].sum())\n",
        "\n",
        "      interacted_distr = {k: v / total for total in (sum(interacted_distr.values()),) for k, v in interacted_distr.items()}\n",
        "\n",
        "      return interacted_distr\n",
        "\n",
        "\n",
        "def CE(P,part_distr):\n",
        "\n",
        "\n",
        "  d3 = {key: abs(P[key] - part_distr.get(key, 0)) for key in P}\n",
        "  if d3=='nan':\n",
        "    return 0\n",
        "\n",
        "  else:\n",
        "    return sum(d3.values())/len(P)\n",
        "\n",
        "\n",
        "def ACE(P,q,N):\n",
        "  all=0\n",
        "  for i in range(N):\n",
        "    part_distr= q_distr(q[0:i+1])\n",
        "\n",
        "    all+= CE(P,part_distr)\n",
        "\n",
        "  return all/N\n",
        "\n",
        "def MACE (P,q,N):\n",
        "  ace=0\n",
        "  for user_id in q.keys():\n",
        "    if user_id in interacted_distr.keys():\n",
        "\n",
        "      ace+=ACE(P[user_id],q[user_id],N) # q here is a list of movies\n",
        "\n",
        "  return ace/len(q.keys())\n",
        "\n",
        "\n",
        "MACE(interacted_distr,final_calibrated_list_kaggle,20)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqiRPL_hUtP2",
        "outputId": "749b60a6-5b1d-4f7d-d5d4-19f3fbae2a65"
      },
      "source": [
        "# MACE\n",
        "\n",
        "#genre\n",
        "# distribution of q\n",
        "\n",
        "def q_distr(list_items):\n",
        "\n",
        "\n",
        "\n",
        "      interacted_distr={}\n",
        "\n",
        "      df_user = df.loc[df['movieId'].isin(list_items)]\n",
        "      df_user= df_user.drop(['Unnamed: 0', 'movieId','title'], axis=1)\n",
        "\n",
        "      for col in df_user.columns:\n",
        "        interacted_distr[col]=(df_user[col].sum())\n",
        "\n",
        "      interacted_distr = {k: v / total for total in (sum(interacted_distr.values()),) for k, v in interacted_distr.items()}\n",
        "\n",
        "      return interacted_distr\n",
        "\n",
        "\n",
        "def CE(P,part_distr):\n",
        "\n",
        "\n",
        "  d3 = {key: abs(P[key] - part_distr.get(key, 0)) for key in P}\n",
        "  if d3=='nan':\n",
        "    return 0\n",
        "\n",
        "  else:\n",
        "    return sum(d3.values())/len(P)\n",
        "\n",
        "\n",
        "def ACE(P,q,N):\n",
        "  all=0\n",
        "  for i in range(N):\n",
        "    part_distr= q_distr(q[0:i+1])\n",
        "\n",
        "    all+= CE(P,part_distr)\n",
        "\n",
        "  return all/N\n",
        "\n",
        "def MACE (P,q,N):\n",
        "  ace=0\n",
        "  for user_id in q.keys():\n",
        "    if user_id in interacted_distr.keys():\n",
        "\n",
        "      ace+=ACE(P[user_id],q[user_id],N) # q here is a list of movies\n",
        "\n",
        "  return ace/len(q.keys())\n",
        "\n",
        "\n",
        "MACE(interacted_distr,final_calibrated_list_kaggle,20)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03999190283400769"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9icqCDZOhr-_"
      },
      "source": [
        "df=pd.read_csv('/content/gdrive/MyDrive/df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjQlzLs9hOr_",
        "outputId": "3d35cd82-187c-47c7-d2bb-5090806f96ce"
      },
      "source": [
        "\n",
        "#genre # different landa (0.8)\n",
        "class CalibratedListProduction():\n",
        "  def __init__(self,lmbda,topn):\n",
        "    self.lmbda=lmbda\n",
        "    self.topn=topn\n",
        "\n",
        "\n",
        "\n",
        "  def compute_kl_divergence(self,interacted_distr, reco_distr, alpha=0.01):\n",
        "      kl_div = 0.\n",
        "      for genre, score in interacted_distr.items():\n",
        "          reco_score = reco_distr.get(genre, 0.)\n",
        "          if score==0 and reco_score==0:\n",
        "            kl_div+=0\n",
        "          else:\n",
        "            reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "            kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "      return kl_div\n",
        "\n",
        "\n",
        "\n",
        "  def compute_utility(self,reco_distr, interacted_distr,total_score):\n",
        "\n",
        "\n",
        "      kl_div = self.compute_kl_divergence(interacted_distr,reco_distr)\n",
        "      # kl divergence is the lower the better, while score is\n",
        "      # the higher the better so remember to negate it in the calculation\n",
        "      utility = (1 - self.lmbda) * total_score - self.lmbda * kl_div\n",
        "      return utility\n",
        "\n",
        "\n",
        "  def calib_recommend(self,candidate,interacted_distr,test_items,predicted_labels,dictionary):\n",
        "\n",
        "      final_calibration_list=[]\n",
        "      calib_distr={}\n",
        "      calib_reco=[]\n",
        "      v={}\n",
        "      for _ in range(self.topn):\n",
        "          max_utility = -np.inf\n",
        "          for item in candidate:  # candidate items\n",
        "\n",
        "\n",
        "              total_score=0\n",
        "              if item in calib_reco: # ignore duplicate items\n",
        "                  continue\n",
        "\n",
        "              probable_calib = calib_reco + [item]\n",
        "\n",
        "\n",
        "              calib_distr={k:dictionary[k] for k in probable_calib if k in dictionary}\n",
        "\n",
        "              h=sum((Counter(d) for d in calib_distr.values()), Counter())\n",
        "              v= {k: v / total for total in (sum(h.values()),) for k, v in h.items()}\n",
        "\n",
        "              k= len(v.keys())\n",
        "              for emotion, score in v.items():\n",
        "                      normalize_emotions = round(score /(k) , 3)\n",
        "                      v[emotion] = normalize_emotions\n",
        "\n",
        "              st = set(probable_calib)\n",
        "\n",
        "              indexes= ([i for i, e in enumerate(test_items) if e in st])\n",
        "\n",
        "              #indexes=[i for i, val in enumerate(test_items) if val in probable_calib]\n",
        "\n",
        "              scores=[]\n",
        "              for i in indexes:\n",
        "\n",
        "                scores.append(predicted_labels[i])\n",
        "              total_score= sum(scores)\n",
        "\n",
        "\n",
        "              #print(\"total_score\", total_score)\n",
        "\n",
        "              utility = self.compute_utility(v,interacted_distr,total_score) # add item to best_item if increase utility of calib_reco\n",
        "\n",
        "              if utility > max_utility:\n",
        "\n",
        "                  max_utility = utility\n",
        "                  best_item = item\n",
        "\n",
        "          calib_reco.append(best_item)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      return calib_reco\n",
        "\n",
        "  def calibrated_final_list(self,candidate_items,test_items ,predicted_labels,rows,interacted_distr,dictionary):\n",
        "\n",
        "    calibrated_recommendations={}\n",
        "\n",
        "\n",
        "    #landa_list=[0,0.3,0.5,0.8,0.9]\n",
        "    for user_id in rows:\n",
        "\n",
        "      if user_id in interacted_distr.keys() & test_items.keys():\n",
        "       calibrated_recommendations[user_id]=self.calib_recommend(candidate_items[user_id], interacted_distr[user_id],test_items[user_id],predicted_labels[user_id],dictionary)\n",
        "\n",
        "    return calibrated_recommendations\n",
        "\n",
        "\n",
        "CalibratedList = CalibratedListProduction(0.8, 20)\n",
        "\n",
        "\n",
        "final_calibrated_list_kaggle =CalibratedList.calibrated_final_list(candidate_items,test_items ,predicted_labels,rows,interacted_distr,dictionary)\n",
        "print(\"completed\")\n",
        "a_file = open(\"/content/gdrive/MyDrive/final_calibrated_list_kaggle.pkl\", \"wb\")\n",
        "pickle.dump(final_calibrated_list_kaggle, a_file)\n",
        "a_file.close()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAYEGfwhbmhM",
        "outputId": "c7dc15c0-0e0f-4b5b-c01b-f9797b1cf1d5"
      },
      "source": [
        "len(final_calibrated_list_kaggle)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPfWtLexbMF-"
      },
      "source": [
        "normal={}\n",
        "for user_id in predicted_labels.keys():\n",
        "\n",
        "  predicted_labels[user_id][:] = [x / sum(predicted_labels[user_id]) for x in predicted_labels[user_id]]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wixi321Bd5ss",
        "outputId": "e604ce87-1485-4a06-dbbd-2800725893ea"
      },
      "source": [
        "sum(list(interacted_distr[4428].values()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "T30VU7wgdgIy",
        "outputId": "2cbb80ca-26e8-4225-c262-ae15424cc16e"
      },
      "source": [
        "# emotion\n",
        "\n",
        "\n",
        "class CalibratedListProduction():\n",
        "  def __init__(self,topn):\n",
        "\n",
        "    self.topn=topn\n",
        "\n",
        "\n",
        "\n",
        "  def compute_kl_divergence(self,interacted_distr, reco_distr, alpha=0.01):\n",
        "      kl_div = 0.\n",
        "\n",
        "      for emotion, score in interacted_distr.items():\n",
        "\n",
        "          reco_score = reco_distr[emotion]\n",
        "          #print(reco_score)\n",
        "          if score==0 and reco_score==0:\n",
        "            kl_div+=0\n",
        "          else:\n",
        "\n",
        "            reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "            kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "      return kl_div\n",
        "\n",
        "\n",
        "\n",
        "  def compute_utility(self,reco_distr, interacted_distr,total_score,lmbda):\n",
        "      \"\"\"\n",
        "      Our objective function for computing the utility score for\n",
        "      the list of recommended items.\n",
        "\n",
        "      lmbda : float, 0.0 ~ 1.0, default 0.5\n",
        "          Lambda term controls the score and calibration tradeoff,\n",
        "          the higher the lambda the higher the resulting recommendation\n",
        "          will be calibrated. Lambda is keyword in Python, so it's\n",
        "          lmbda instead ^^\n",
        "      \"\"\"\n",
        "      #print(\"reco\", reco_distr)\n",
        "      kl_div = self.compute_kl_divergence(interacted_distr,reco_distr)\n",
        "      # kl divergence is the lower the better, while score is\n",
        "      # the higher the better so remember to negate it in the calculation\n",
        "      utility = (1 - lmbda) * total_score - lmbda * kl_div\n",
        "      return utility\n",
        "\n",
        "\n",
        "  def calib_recommend(self,candidate,interacted_distr,test_items,predicted_labels,tagsdf,lmbda):\n",
        "\n",
        "      \"\"\"\n",
        "      start with an empty recommendation list,\n",
        "      loop over the topn cardinality, during each iteration\n",
        "      update the list with the item that maximizes the utility function.\n",
        "      \"\"\"\n",
        "      calib_reco=[]\n",
        "      calib_distr={}\n",
        "      for _ in range(self.topn):\n",
        "          max_utility = -np.inf\n",
        "          for item in candidate:  # candidate items\n",
        "\n",
        "\n",
        "              total_score=0\n",
        "              if item in calib_reco: # ignore duplicate items\n",
        "                  continue\n",
        "\n",
        "              probable_calib = calib_reco + [item]\n",
        "\n",
        "\n",
        "              df_calib =tagsdf.loc[tagsdf['movieId'].isin(probable_calib)]\n",
        "\n",
        "              df_calib= df_calib.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "              for col in df_calib.columns:\n",
        "                calib_distr[col]=df_calib[col].sum()\n",
        "              calib_distr= {k: v / total for total in (sum(calib_distr.values()),) for k, v in calib_distr.items()}\n",
        "              k= len(calib_distr.keys())\n",
        "              for emotion, score in calib_distr.items():\n",
        "                normalize_emotions = round(score /(k) , 3)\n",
        "                calib_distr[emotion] = normalize_emotions\n",
        "              st = set(probable_calib)\n",
        "              indexes= ([i for i, e in enumerate(test_items) if e in st])\n",
        "\n",
        "              #indexes=[i for i, val in enumerate(test_items) if val in probable_calib]\n",
        "\n",
        "              scores=[]\n",
        "              for i in indexes:\n",
        "                #print('predi',predicted_labels[i])\n",
        "\n",
        "                scores.append(predicted_labels[i])\n",
        "              #print(scores)\n",
        "\n",
        "              total_score= sum(scores)\n",
        "\n",
        "              #print(\"total_score\", total_score)\n",
        "\n",
        "              utility = self.compute_utility(calib_distr,interacted_distr,total_score,lmbda) # add item to best_item if increase utility of calib_reco\n",
        "              if utility > max_utility:\n",
        "                  max_utility = utility\n",
        "                  best_item = item\n",
        "\n",
        "          calib_reco.append(best_item)\n",
        "\n",
        "      return calib_reco\n",
        "\n",
        "\n",
        "\n",
        "  def calibrated_final_list(self,interacted_items_kaggle,candidate_items,test_items,predicted_labels,rows,interacted_distr,tagsdf):\n",
        "    custom= variance(rows,interacted_distr)\n",
        "    calibrated_recommendations={}\n",
        "    max=-1000\n",
        "    for user_id in rows:\n",
        "      landa_value={}\n",
        "      lmbda_list=[0.3,0.5,0,0.8,0.9,custom[user_id]]\n",
        "      predicted=predicted_labels[user_id]\n",
        "      for landa in lmbda_list:\n",
        "        calib=self.calib_recommend(candidate_items[user_id], interacted_distr[user_id],test_items[user_id],predicted_labels[user_id],tagsdf,landa)\n",
        "        scores=[]\n",
        "        distr_here={}\n",
        "\n",
        "\n",
        "        df_calib =tagsdf.loc[tagsdf['movieId'].isin(calib)]\n",
        "        #print(df_calib)\n",
        "        df_calib= df_calib.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "        for col in df_calib.columns:\n",
        "          distr_here[col]=df_calib[col].sum()\n",
        "\n",
        "        distr_here= {k: v / total for total in (sum(distr_here.values()),) for k, v in distr_here.items()}\n",
        "\n",
        "        for emotion, score in distr_here.items():\n",
        "          normalize_emotions = round(score /(k) , 3)\n",
        "          distr_here[emotion] = normalize_emotions\n",
        "\n",
        "        kld= self.compute_kl_divergence(interacted_distr[user_id],distr_here)\n",
        "        st = set(calib)\n",
        "        #print(calib)\n",
        "        indexes= ([i for i, e in enumerate(test_items[user_id]) if e in st])\n",
        "\n",
        "        #print(indexes)\n",
        "        for item in indexes:\n",
        "          #print(item)\n",
        "          scores.append(predicted[item])\n",
        "        print(sum(scores))\n",
        "        print(kld)\n",
        "        comp= landa*(kld) + (1-landa) *sum(scores)\n",
        "        if comp>max:\n",
        "          max=comp\n",
        "          calib_reco= calib\n",
        "          max_landa=landa\n",
        "          calibrated_recommendations[user_id]=calib_reco\n",
        "          #print(calibrated_recommendations)\n",
        "          landa_value[user_id]=landa\n",
        "          print(landa_value)\n",
        "\n",
        "\n",
        "    return calibrated_recommendations,land_value\n",
        "\n",
        "\n",
        "CalibratedList = CalibratedListProduction(20)\n",
        "#rows= conversion(finall_test_rows,finall_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "final_calibrated_list_kaggle, values =CalibratedList.calibrated_final_list(interacted_items_kaggle,candidate_items,test_items ,predicted_labels,rows,interacted_distr,tagsdf)\n",
        "print(\"completed\")\n",
        "\"\"\"a_file = open(\"/content/gdrive/MyDrive/final_calibrated_list_kaggle_0.8_smallest.pkl\", \"wb\")\n",
        "pickle.dump(final_calibrated_list_kaggle, a_file)\n",
        "a_file.close()\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:73: RuntimeWarning: invalid value encountered in double_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2778987353667617\n",
            "-0.46206802412243014\n",
            "{22979: 0.3}\n",
            "0.2778987353667617\n",
            "-0.46206802412243014\n",
            "0.2778987353667617\n",
            "-0.46206802412243014\n",
            "{22979: 0}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-822f8b8c2a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m \u001b[0mfinal_calibrated_list_kaggle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mCalibratedList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrated_final_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteracted_items_kaggle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcandidate_items\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_items\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minteracted_distr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtagsdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"completed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \"\"\"a_file = open(\"/content/gdrive/MyDrive/final_calibrated_list_kaggle_0.8_smallest.pkl\", \"wb\")\n",
            "\u001b[0;32m<ipython-input-70-822f8b8c2a98>\u001b[0m in \u001b[0;36mcalibrated_final_list\u001b[0;34m(self, interacted_items_kaggle, candidate_items, test_items, predicted_labels, rows, interacted_distr, tagsdf)\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0mpredicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlanda\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlmbda_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mcalib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalib_recommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteracted_distr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtagsdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlanda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mdistr_here\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-822f8b8c2a98>\u001b[0m in \u001b[0;36mcalib_recommend\u001b[0;34m(self, candidate, interacted_distr, test_items, predicted_labels, tagsdf, lmbda)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m               \u001b[0mdf_calib\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtagsdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtagsdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobable_calib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m               \u001b[0mdf_calib\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf_calib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'movieId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36misin\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   4696\u001b[0m         \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0manimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4697\u001b[0m         \"\"\"\n\u001b[0;32m-> 4698\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4699\u001b[0m         return self._constructor(result, index=self.index).__finalize__(\n\u001b[1;32m   4700\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"isin\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36misin\u001b[0;34m(comps, values)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0mcomps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;31m# TODO(extension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# handle categoricals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/base.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m             \u001b[0;31m# https://github.com/pandas-dev/pandas/issues/22960\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;31m# avoid passing data to `construct_from_string`. This could\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_typ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__instancecheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAo4vPRU2Vz7"
      },
      "source": [
        "custom= variance(rows,interacted_distr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWy3TB5rA8nZ",
        "outputId": "d8d06f33-cc6b-49bb-f287-eb170015c374"
      },
      "source": [
        "custom[91089]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9851612473192618"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjCdI7kjZVco"
      },
      "source": [
        "def compute_kl_divergence(interacted_distr, reco_distr, alpha=0.01):\n",
        "      kl_div = 0.\n",
        "      for genre, score in interacted_distr.items():\n",
        "          reco_score = reco_distr.get(genre, 0.)\n",
        "          if score==0 and reco_score==0:\n",
        "            kl_div+=0\n",
        "          else:\n",
        "            reco_score = (1 - alpha) * reco_score + alpha * score\n",
        "            kl_div += score * np.log2(score / reco_score)\n",
        "\n",
        "      return kl_div\n",
        "predicted=predicted_labels[user]\n",
        "score=[]\n",
        "comp=[]\n",
        "df_calib =tagsdf.loc[tagsdf['movieId'].isin(recommended)]\n",
        "df_calib= df_calib.drop(['Unnamed: 0', 'movieId'], axis=1)\n",
        "for col in df_calib.columns:\n",
        "  calib_distr[col]=df_calib[col].sum()\n",
        "  calib_distr= {k: v / total for total in (sum(calib_distr.values()),) for k, v in calib_distr.items()}\n",
        "kld= compute_kl_divergence(interacted_distr,calib_distr)\n",
        "\n",
        "for item in recommended:\n",
        "  score.append(predicted[i])\n",
        "comp[lmbda]= lmbda(kld) + (1-lmbda)sum(score)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}